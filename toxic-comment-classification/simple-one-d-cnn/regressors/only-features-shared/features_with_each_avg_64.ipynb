{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10373,
     "status": "ok",
     "timestamp": 1530913456924,
     "user": {
      "displayName": "Deep Learning",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115257841230779963257"
     },
     "user_tz": -120
    },
    "id": "yS1FnhiWX3Js",
    "outputId": "f9c02018-c003-4950-ba4d-a5da1082aa63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.1.6)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.12)\r\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.5)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (0.19.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.19.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (2.1.2)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2018.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.2.0)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.14.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install sklearn\n",
    "!pip install matplotlib\n",
    "!pip install -U -q PyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1596,
     "status": "ok",
     "timestamp": 1530913458635,
     "user": {
      "displayName": "Deep Learning",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115257841230779963257"
     },
     "user_tz": -120
    },
    "id": "xlKzkDJFrjA-",
    "outputId": "2e71de97-52f7-4549-d844-e959d05c740c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eQEKwl4oAxO7"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "cfg = K.tf.ConfigProto()\n",
    "cfg.gpu_options.allow_growth = True\n",
    "K.set_session(K.tf.Session(config=cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "12M0egCCX-27"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4lN2WTUEYBYv"
   },
   "outputs": [],
   "source": [
    "file_import = drive.CreateFile({'id':'1p1bsltfTcIrZ_kfE6kwGTPzcdXorHbb2'})\n",
    "file_import.GetContentFile('colab_setup.py') \n",
    "from colab_setup import setup\n",
    "\n",
    "setup(drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1636,
     "status": "ok",
     "timestamp": 1530913489014,
     "user": {
      "displayName": "Deep Learning",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115257841230779963257"
     },
     "user_tz": -120
    },
    "id": "cHBlD0tVj2TY",
    "outputId": "7078c694-9ad2-4775-b4f3-3afd36e7db7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colab_setup.py\t\t\t sample_submission.csv\tX_val.npy\r\n",
      "custom_fast_text_embeddings.npy  SelfAttention.py\ty_test.npy\r\n",
      "datalab\t\t\t\t train_model.py\t\ty_train_full.npy\r\n",
      "fast_text_embeddings.npy\t X_submission.npy\ty_train.npy\r\n",
      "plot_history.py\t\t\t X_test.npy\t\ty_val.npy\r\n",
      "__pycache__\t\t\t X_train_full.npy\r\n",
      "roc_auc_callback.py\t\t X_train.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yMwWPTMYXyno"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from plot_history import plot_history\n",
    "from roc_auc_callback import RocAucCallback\n",
    "from train_model import train_with_cv, train_with_submitting, evaluate_on_test\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3YXiQ6IRovcY"
   },
   "outputs": [],
   "source": [
    "file_import = drive.CreateFile({'id':'15j1Nou6m5WNLejJQrUcty6U03xsIgIAI'})\n",
    "file_import.GetContentFile('SelfAttention.py') \n",
    "\n",
    "from SelfAttention import SelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MIWjPi9bs5d4"
   },
   "outputs": [],
   "source": [
    "def one_by_one(filtersNumber, inputLayer, dropout = 0.2):\n",
    "    one_by_one = Conv1D(filtersNumber, 1, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(inputLayer)\n",
    "    one_by_one = BatchNormalization()(one_by_one)\n",
    "    one_by_one = SpatialDropout1D(dropout)(one_by_one)\n",
    "    \n",
    "    return one_by_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mRg7bBAFoL7b"
   },
   "outputs": [],
   "source": [
    "def yoon_kim_feature_extractor(filtersNumber, inputLayer):\n",
    "    block_1_conv_1 = Conv1D(filtersNumber, 1, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(inputLayer)\n",
    "    block_1_batchnorm1 = BatchNormalization()(block_1_conv_1)\n",
    "    block_1_max_pool1 = GlobalMaxPooling1D()(block_1_batchnorm1)\n",
    "\n",
    "    block_1_conv_2 = Conv1D(filtersNumber, 2, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(inputLayer)\n",
    "    block_1_batchnorm2 = BatchNormalization()(block_1_conv_2)\n",
    "    block_1_max_pool2 = GlobalMaxPooling1D()(block_1_batchnorm2)\n",
    "\n",
    "    block_1_conv_3 = Conv1D(filtersNumber, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(inputLayer)\n",
    "    block_1_batchnorm3 = BatchNormalization()(block_1_conv_3)\n",
    "    block_1_max_pool3 = GlobalMaxPooling1D()(block_1_batchnorm3)\n",
    "\n",
    "    block_1_conv_4 = Conv1D(filtersNumber, 5, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(inputLayer)\n",
    "    block_1_batchnorm4 = BatchNormalization()(block_1_conv_4)\n",
    "    block_1_max_pool4 = GlobalMaxPooling1D()(block_1_batchnorm4)\n",
    "\n",
    "    block_1_features = concatenate([\n",
    "        block_1_max_pool1, \n",
    "        block_1_max_pool2, \n",
    "        block_1_max_pool3, \n",
    "        block_1_max_pool4\n",
    "    ])\n",
    "    block_1_features = Dropout(0.2)(block_1_features)\n",
    "    return block_1_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nil0V0anLg2Y"
   },
   "outputs": [],
   "source": [
    "def single_category_regressor(features, unitsNumber = 64):\n",
    "    dense_1 = Dense(unitsNumber, activation = 'elu')(features)\n",
    "    dense_1_normalization = BatchNormalization()(dense_1)\n",
    "    dense_1_dropout = Dropout(0.2)(dense_1_normalization)\n",
    "\n",
    "    dense_2 = Dense(unitsNumber, activation = 'elu')(dense_1_dropout)\n",
    "    dense_2_normalization = BatchNormalization()(dense_2)\n",
    "    dense_2_dropout = Dropout(0.2)(dense_2_normalization)\n",
    "    \n",
    "    return Dense(1, activation='sigmoid')(dense_2_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3094
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4605,
     "status": "ok",
     "timestamp": 1530913497691,
     "user": {
      "displayName": "Deep Learning",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115257841230779963257"
     },
     "user_tz": -120
    },
    "id": "LTFG7OgsXynw",
    "outputId": "691506b5-6dd8-496b-c17f-5f6740736036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 400)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 400, 300)     9000000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 400, 300)     9000000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 400, 300)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 400, 300)     0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "average_1 (Average)             (None, 400, 300)     0           spatial_dropout1d_1[0][0]        \n",
      "                                                                 spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 400, 300)     0           average_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_1 (SelfAttention (None, 400, 300)     90601       spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 400, 300)     90300       self_attention_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 400, 300)     1200        conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 400, 300)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 400, 300)     90300       spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 400, 300)     1200        conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 400, 300)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 400, 300)     90300       spatial_dropout1d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 400, 300)     1200        conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 400, 300)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 400, 300)     90300       spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 400, 300)     180300      spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 400, 300)     270300      spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 400, 300)     450300      spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 400, 300)     1200        conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 400, 300)     1200        conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 400, 300)     1200        conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 400, 300)     1200        conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 300)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 300)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 300)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 300)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1200)         0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1200)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           76864       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           76864       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 64)           76864       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 64)           76864       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 64)           76864       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 64)           76864       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          307456      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64)           256         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64)           256         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64)           256         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64)           256         dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 64)           256         dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 64)           256         dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 256)          1024        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64)           0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64)           0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 64)           0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 64)           0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 64)           0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 64)           0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           4160        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 64)           4160        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 64)           4160        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 64)           4160        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 64)           4160        dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 64)           4160        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          65792       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64)           256         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64)           256         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64)           256         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64)           256         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 64)           256         dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 64)           256         dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 256)          1024        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 64)           0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64)           0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 64)           0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 64)           0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 64)           0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 64)           0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256)          0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            65          dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            65          dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            65          dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1)            65          dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 1)            65          dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1)            65          dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 6)            1542        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 6)            0           dense_8[0][0]                    \n",
      "                                                                 dense_11[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "                                                                 dense_17[0][0]                   \n",
      "                                                                 dense_20[0][0]                   \n",
      "                                                                 dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_2 (Average)             (None, 6)            0           dense_5[0][0]                    \n",
      "                                                                 concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 20,227,545\n",
      "Trainable params: 2,220,785\n",
      "Non-trainable params: 18,006,760\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "maxWords = 30000\n",
    "maxSequenceLengthInWords = 400\n",
    "embeddingDimension = 300\n",
    "filtersNumber = 300\n",
    "\n",
    "input_layer = Input(shape=(maxSequenceLengthInWords,))\n",
    "\n",
    "pretrained_embedding_layer = Embedding(\n",
    "    maxWords, \n",
    "    output_dim=embeddingDimension, \n",
    "    input_length=maxSequenceLengthInWords,\n",
    "    weights = [np.load('fast_text_embeddings.npy')],\n",
    "    trainable = False\n",
    ")(input_layer)\n",
    "pretrained_embedding_layer = SpatialDropout1D(0.2)(pretrained_embedding_layer)\n",
    "\n",
    "custom_embedding_layer = Embedding(\n",
    "    maxWords, \n",
    "    output_dim=embeddingDimension, \n",
    "    input_length=maxSequenceLengthInWords,\n",
    "    weights = [np.load('custom_fast_text_embeddings.npy')],\n",
    "    trainable = False\n",
    ")(input_layer)\n",
    "custom_embedding_layer = SpatialDropout1D(0.2)(custom_embedding_layer)\n",
    "\n",
    "embedding = Average()([pretrained_embedding_layer, custom_embedding_layer])\n",
    "embedding_dropout = SpatialDropout1D(0.2)(embedding)\n",
    "\n",
    "embedding_dropout = SelfAttention()(embedding_dropout)\n",
    "\n",
    "features_1 = one_by_one(filtersNumber, embedding_dropout)\n",
    "features_2 = one_by_one(filtersNumber, features_1)\n",
    "features_3 = one_by_one(filtersNumber, features_2)\n",
    "\n",
    "features = yoon_kim_feature_extractor(filtersNumber, features_3)\n",
    "\n",
    "dense_1 = Dense(256, activation = 'elu')(features)\n",
    "dense_1_normalization = BatchNormalization()(dense_1)\n",
    "dense_1_dropout = Dropout(0.2)(dense_1_normalization)\n",
    "\n",
    "dense_2 = Dense(256, activation = 'elu')(dense_1_dropout)\n",
    "dense_2_normalization = BatchNormalization()(dense_2)\n",
    "dense_2_dropout = Dropout(0.2)(dense_2_normalization)\n",
    "\n",
    "output_layer = Dense(6, activation='sigmoid')(dense_2_dropout)\n",
    "\n",
    "single_category_layer = concatenate([\n",
    "    single_category_regressor(features, 64),\n",
    "    single_category_regressor(features, 64),\n",
    "    single_category_regressor(features, 64),\n",
    "    single_category_regressor(features, 64),\n",
    "    single_category_regressor(features, 64),\n",
    "    single_category_regressor(features, 64),\n",
    "])\n",
    "\n",
    "output_layer = average([output_layer, single_category_layer])\n",
    "\n",
    "model = Model(inputs=[input_layer], outputs=[output_layer])\n",
    "            \n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1482
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24362311,
     "status": "ok",
     "timestamp": 1530913086944,
     "user": {
      "displayName": "Deep Learning",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115257841230779963257"
     },
     "user_tz": -120
    },
    "id": "xwMmTewgXynz",
    "outputId": "4ffe853b-19ce-4418-fdf2-a38f40d641b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 102124 samples, validate on 25532 samples\n",
      "Epoch 1/32\n",
      " 19808/102124 [====>.........................] - ETA: 9:22 - loss: 0.1967 - acc: 0.9211 54848/102124 [===============>..............] - ETA: 5:00 - loss: 0.1220 - acc: 0.9531 89280/102124 [=========================>....] - ETA: 1:20 - loss: 0.1031 - acc: 0.9608102124/102124 [==============================] - 678s 7ms/step - loss: 0.0988 - acc: 0.9626 - val_loss: 0.0802 - val_acc: 0.9753\n",
      "Epoch 2/32\n",
      "  8256/102124 [=>............................] - ETA: 9:30 - loss: 0.0649 - acc: 0.9762 41056/102124 [===========>..................] - ETA: 6:16 - loss: 0.0652 - acc: 0.9765 74432/102124 [====================>.........] - ETA: 2:50 - loss: 0.0646 - acc: 0.9768102124/102124 [==============================] - 668s 7ms/step - loss: 0.0634 - acc: 0.9772 - val_loss: 0.0850 - val_acc: 0.9706\n",
      "roc-auc: 0.9702 - roc-auc_val: 0.9684                                                                                                    \n",
      "Epoch 3/32\n",
      "  1408/102124 [..............................] - ETA: 10:11 - loss: 0.0545 - acc: 0.9806 35392/102124 [=========>....................] - ETA: 6:49 - loss: 0.0569 - acc: 0.9794 69632/102124 [===================>..........] - ETA: 3:19 - loss: 0.0569 - acc: 0.9795102124/102124 [==============================] - 668s 7ms/step - loss: 0.0564 - acc: 0.9795 - val_loss: 0.0537 - val_acc: 0.9817\n",
      "Epoch 4/32\n",
      "   256/102124 [..............................] - ETA: 10:30 - loss: 0.0656 - acc: 0.9766 34176/102124 [=========>....................] - ETA: 6:56 - loss: 0.0545 - acc: 0.9801 69600/102124 [===================>..........] - ETA: 3:19 - loss: 0.0534 - acc: 0.9801102124/102124 [==============================] - 666s 7ms/step - loss: 0.0522 - acc: 0.9805 - val_loss: 0.0527 - val_acc: 0.9812\n",
      "roc-auc: 0.979 - roc-auc_val: 0.9769                                                                                                    \n",
      "Epoch 5/32\n",
      "   448/102124 [..............................] - ETA: 10:21 - loss: 0.0537 - acc: 0.9818 34336/102124 [=========>....................] - ETA: 6:56 - loss: 0.0511 - acc: 0.9811 68992/102124 [===================>..........] - ETA: 3:23 - loss: 0.0505 - acc: 0.9812102124/102124 [==============================] - 666s 7ms/step - loss: 0.0502 - acc: 0.9812 - val_loss: 0.0479 - val_acc: 0.9820\n",
      "Epoch 6/32\n",
      "   384/102124 [..............................] - ETA: 10:25 - loss: 0.0523 - acc: 0.9792 34624/102124 [=========>....................] - ETA: 6:53 - loss: 0.0485 - acc: 0.9818 68544/102124 [===================>..........] - ETA: 3:25 - loss: 0.0488 - acc: 0.9817102112/102124 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9818102124/102124 [==============================] - 667s 7ms/step - loss: 0.0484 - acc: 0.9818 - val_loss: 0.0452 - val_acc: 0.9825\n",
      "roc-auc: 0.9845 - roc-auc_val: 0.981                                                                                                    \n",
      "Epoch 7/32\n",
      "  8320/102124 [=>............................] - ETA: 9:27 - loss: 0.0483 - acc: 0.982 43104/102124 [===========>..................] - ETA: 5:58 - loss: 0.0470 - acc: 0.9820 79392/102124 [======================>.......] - ETA: 2:18 - loss: 0.0472 - acc: 0.9820102124/102124 [==============================] - 660s 6ms/step - loss: 0.0473 - acc: 0.9820 - val_loss: 0.0449 - val_acc: 0.9825\n",
      "Epoch 8/32\n",
      "  4512/102124 [>.............................] - ETA: 9:52 - loss: 0.0491 - acc: 0.9810 39264/102124 [==========>...................] - ETA: 6:22 - loss: 0.0474 - acc: 0.9819 73824/102124 [====================>.........] - ETA: 2:52 - loss: 0.0464 - acc: 0.9821102124/102124 [==============================] - 662s 6ms/step - loss: 0.0465 - acc: 0.9820 - val_loss: 0.0446 - val_acc: 0.9830\n",
      "roc-auc: 0.9866 - roc-auc_val: 0.9827                                                                                                    \n",
      "Epoch 9/32\n",
      "  1440/102124 [..............................] - ETA: 10:21 - loss: 0.0468 - acc: 0.9811 35648/102124 [=========>....................] - ETA: 6:44 - loss: 0.0464 - acc: 0.9821 70496/102124 [===================>..........] - ETA: 3:12 - loss: 0.0454 - acc: 0.9826102124/102124 [==============================] - 661s 6ms/step - loss: 0.0455 - acc: 0.9824 - val_loss: 0.0432 - val_acc: 0.9829\n",
      "Epoch 10/32\n",
      "   928/102124 [..............................] - ETA: 10:24 - loss: 0.0407 - acc: 0.9849 35968/102124 [=========>....................] - ETA: 6:45 - loss: 0.0446 - acc: 0.9828 70368/102124 [===================>..........] - ETA: 3:14 - loss: 0.0447 - acc: 0.9827102124/102124 [==============================] - 666s 7ms/step - loss: 0.0446 - acc: 0.9826 - val_loss: 0.0434 - val_acc: 0.9828\n",
      "roc-auc: 0.9901 - roc-auc_val: 0.9847                                                                                                    \n",
      "Epoch 11/32\n",
      "   384/102124 [..............................] - ETA: 10:17 - loss: 0.0482 - acc: 0.9796 34784/102124 [=========>....................] - ETA: 6:52 - loss: 0.0443 - acc: 0.9824 68352/102124 [===================>..........] - ETA: 3:27 - loss: 0.0433 - acc: 0.9829101600/102124 [============================>.] - ETA: 3s - loss: 0.0440 - acc: 0.9827102124/102124 [==============================] - 666s 7ms/step - loss: 0.0441 - acc: 0.9827 - val_loss: 0.0421 - val_acc: 0.9835\n",
      "Epoch 12/32\n",
      " 12800/102124 [==>...........................] - ETA: 9:05 - loss: 0.0428 - acc: 0.9828 46336/102124 [============>.................] - ETA: 5:42 - loss: 0.0439 - acc: 0.9828 79552/102124 [======================>.......] - ETA: 2:18 - loss: 0.0437 - acc: 0.9828102124/102124 [==============================] - 665s 7ms/step - loss: 0.0434 - acc: 0.9828 - val_loss: 0.0471 - val_acc: 0.9822\n",
      "roc-auc: 0.9863 - roc-auc_val: 0.9805                                                                                                    \n",
      "Epoch 13/32\n",
      "  2720/102124 [..............................] - ETA: 10:13 - loss: 0.0414 - acc: 0.9837 36224/102124 [=========>....................] - ETA: 6:42 - loss: 0.0425 - acc: 0.9833 69376/102124 [===================>..........] - ETA: 3:20 - loss: 0.0431 - acc: 0.9830102124/102124 [==============================] - 663s 6ms/step - loss: 0.0430 - acc: 0.9830 - val_loss: 0.0448 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00014358729822561145.\n",
      "Epoch 14/32\n",
      "   128/102124 [..............................] - ETA: 10:27 - loss: 0.0376 - acc: 0.9857 34464/102124 [=========>....................] - ETA: 6:53 - loss: 0.0420 - acc: 0.9835 68672/102124 [===================>..........] - ETA: 3:24 - loss: 0.0427 - acc: 0.9832102112/102124 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9832102124/102124 [==============================] - 664s 7ms/step - loss: 0.0425 - acc: 0.9832 - val_loss: 0.0416 - val_acc: 0.9837\n",
      "roc-auc: 0.9912 - roc-auc_val: 0.9862                                                                                                    \n",
      "Epoch 15/32\n",
      "  8096/102124 [=>............................] - ETA: 9:37 - loss: 0.0450 - acc: 0.9824 41472/102124 [===========>..................] - ETA: 6:10 - loss: 0.0423 - acc: 0.9834 77472/102124 [=====================>........] - ETA: 2:30 - loss: 0.0419 - acc: 0.9835102124/102124 [==============================] - 662s 6ms/step - loss: 0.0421 - acc: 0.9835 - val_loss: 0.0408 - val_acc: 0.9840\n",
      "Epoch 16/32\n",
      "  3488/102124 [>.............................] - ETA: 9:57 - loss: 0.0404 - acc: 0.9833 40768/102124 [==========>...................] - ETA: 6:13 - loss: 0.0425 - acc: 0.9830 76640/102124 [=====================>........] - ETA: 2:35 - loss: 0.0419 - acc: 0.9833102124/102124 [==============================] - 662s 6ms/step - loss: 0.0418 - acc: 0.9834 - val_loss: 0.0415 - val_acc: 0.9836\n",
      "roc-auc: 0.9911 - roc-auc_val: 0.9858                                                                                                    \n",
      "Epoch 17/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1888/102124 [..............................] - ETA: 10:16 - loss: 0.0432 - acc: 0.9829 36992/102124 [=========>....................] - ETA: 6:38 - loss: 0.0408 - acc: 0.9837 71392/102124 [===================>..........] - ETA: 3:07 - loss: 0.0410 - acc: 0.9838102124/102124 [==============================] - 664s 7ms/step - loss: 0.0412 - acc: 0.9837 - val_loss: 0.0416 - val_acc: 0.9837\n",
      "Epoch 18/32\n",
      "  1344/102124 [..............................] - ETA: 10:17 - loss: 0.0401 - acc: 0.9833 35104/102124 [=========>....................] - ETA: 6:50 - loss: 0.0403 - acc: 0.9840 69184/102124 [===================>..........] - ETA: 3:22 - loss: 0.0408 - acc: 0.9837102124/102124 [==============================] - 666s 7ms/step - loss: 0.0409 - acc: 0.9838 - val_loss: 0.0438 - val_acc: 0.9836\n",
      "roc-auc: 0.9901 - roc-auc_val: 0.983                                                                                                    \n",
      "Epoch 19/32\n",
      "   128/102124 [..............................] - ETA: 10:35 - loss: 0.0246 - acc: 0.9935 35008/102124 [=========>....................] - ETA: 6:50 - loss: 0.0407 - acc: 0.9838 69792/102124 [===================>..........] - ETA: 3:17 - loss: 0.0404 - acc: 0.9839102124/102124 [==============================] - 662s 6ms/step - loss: 0.0406 - acc: 0.9839 - val_loss: 0.0411 - val_acc: 0.9839\n",
      "Epoch 20/32\n",
      "   704/102124 [..............................] - ETA: 10:24 - loss: 0.0415 - acc: 0.9837 34272/102124 [=========>....................] - ETA: 6:53 - loss: 0.0401 - acc: 0.9836 68128/102124 [===================>..........] - ETA: 3:27 - loss: 0.0405 - acc: 0.9838102112/102124 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9837102124/102124 [==============================] - 662s 6ms/step - loss: 0.0406 - acc: 0.9837 - val_loss: 0.0405 - val_acc: 0.9841\n",
      "roc-auc: 0.9928 - roc-auc_val: 0.9869                                                                                                    \n",
      "Epoch 21/32\n",
      "  7936/102124 [=>............................] - ETA: 9:37 - loss: 0.0437 - acc: 0.9831 42144/102124 [===========>..................] - ETA: 6:06 - loss: 0.0403 - acc: 0.9839 75872/102124 [=====================>........] - ETA: 2:40 - loss: 0.0402 - acc: 0.9839102124/102124 [==============================] - 663s 6ms/step - loss: 0.0404 - acc: 0.9839 - val_loss: 0.0401 - val_acc: 0.9843\n",
      "Epoch 22/32\n",
      "  2912/102124 [..............................] - ETA: 10:03 - loss: 0.0410 - acc: 0.9839 38048/102124 [==========>...................] - ETA: 6:30 - loss: 0.0410 - acc: 0.9836 72352/102124 [====================>.........] - ETA: 3:01 - loss: 0.0405 - acc: 0.9837102124/102124 [==============================] - 664s 7ms/step - loss: 0.0401 - acc: 0.9839 - val_loss: 0.0405 - val_acc: 0.9840\n",
      "roc-auc: 0.9931 - roc-auc_val: 0.987                                                                                                    \n",
      "Epoch 23/32\n",
      "  1216/102124 [..............................] - ETA: 10:16 - loss: 0.0410 - acc: 0.9834 34848/102124 [=========>....................] - ETA: 6:50 - loss: 0.0390 - acc: 0.9844 68864/102124 [===================>..........] - ETA: 3:23 - loss: 0.0396 - acc: 0.9841102124/102124 [==============================] - 662s 6ms/step - loss: 0.0398 - acc: 0.9842 - val_loss: 0.0401 - val_acc: 0.9842\n",
      "Epoch 24/32\n",
      "   544/102124 [..............................] - ETA: 10:30 - loss: 0.0377 - acc: 0.9856 35936/102124 [=========>....................] - ETA: 6:43 - loss: 0.0383 - acc: 0.9847 71264/102124 [===================>..........] - ETA: 3:07 - loss: 0.0393 - acc: 0.9844102124/102124 [==============================] - 660s 6ms/step - loss: 0.0396 - acc: 0.9843 - val_loss: 0.0404 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.575267666950822e-05.\n",
      "roc-auc: 0.9932 - roc-auc_val: 0.9869                                                                                                    \n",
      "Epoch 25/32\n",
      "   704/102124 [..............................] - ETA: 10:28 - loss: 0.0397 - acc: 0.9837 35584/102124 [=========>....................] - ETA: 6:42 - loss: 0.0396 - acc: 0.9843 73120/102124 [====================>.........] - ETA: 2:55 - loss: 0.0395 - acc: 0.9842102124/102124 [==============================] - 659s 6ms/step - loss: 0.0396 - acc: 0.9842 - val_loss: 0.0408 - val_acc: 0.9839\n",
      "Epoch 26/32\n",
      "  1664/102124 [..............................] - ETA: 10:23 - loss: 0.0395 - acc: 0.9856 35520/102124 [=========>....................] - ETA: 6:46 - loss: 0.0390 - acc: 0.9846 71392/102124 [===================>..........] - ETA: 3:06 - loss: 0.0397 - acc: 0.9842102124/102124 [==============================] - 660s 6ms/step - loss: 0.0393 - acc: 0.9842 - val_loss: 0.0402 - val_acc: 0.9841\n",
      "roc-auc: 0.9934 - roc-auc_val: 0.9871                                                                                                    \n",
      "Epoch 27/32\n",
      "   864/102124 [..............................] - ETA: 10:06 - loss: 0.0362 - acc: 0.9846 36256/102124 [=========>....................] - ETA: 6:38 - loss: 0.0409 - acc: 0.9835 73696/102124 [====================>.........] - ETA: 2:51 - loss: 0.0396 - acc: 0.9842102124/102124 [==============================] - 657s 6ms/step - loss: 0.0395 - acc: 0.9843 - val_loss: 0.0407 - val_acc: 0.9841\n",
      "Epoch 28/32\n",
      "  2048/102124 [..............................] - ETA: 10:20 - loss: 0.0352 - acc: 0.98 37504/102124 [==========>...................] - ETA: 6:32 - loss: 0.0397 - acc: 0.9840 76192/102124 [=====================>........] - ETA: 2:36 - loss: 0.0394 - acc: 0.9842102124/102124 [==============================] - 658s 6ms/step - loss: 0.0392 - acc: 0.9843 - val_loss: 0.0405 - val_acc: 0.9842\n",
      "roc-auc: 0.9931 - roc-auc_val: 0.9864                                                                                                    \n",
      "Epoch 29/32\n",
      "  2176/102124 [..............................] - ETA: 10:05 - loss: 0.0386 - acc: 0.9845 39680/102124 [==========>...................] - ETA: 6:19 - loss: 0.0387 - acc: 0.9847 74560/102124 [====================>.........] - ETA: 2:47 - loss: 0.0388 - acc: 0.9845102124/102124 [==============================] - 660s 6ms/step - loss: 0.0392 - acc: 0.9844 - val_loss: 0.0402 - val_acc: 0.9843\n",
      "Epoch 30/32\n",
      "  2656/102124 [..............................] - ETA: 10:18 - loss: 0.0369 - acc: 0.9858 40672/102124 [==========>...................] - ETA: 6:13 - loss: 0.0389 - acc: 0.9843 79456/102124 [======================>.......] - ETA: 2:17 - loss: 0.0388 - acc: 0.9843102124/102124 [==============================] - 659s 6ms/step - loss: 0.0388 - acc: 0.9843 - val_loss: 0.0403 - val_acc: 0.9841\n",
      "roc-auc: 0.9935 - roc-auc_val: 0.9871                                                                                                    \n",
      "Epoch 31/32\n",
      "  2848/102124 [..............................] - ETA: 10:02 - loss: 0.0363 - acc: 0.9858 38432/102124 [==========>...................] - ETA: 6:27 - loss: 0.0392 - acc: 0.9843 74752/102124 [====================>.........] - ETA: 2:46 - loss: 0.0395 - acc: 0.9844102124/102124 [==============================] - 660s 6ms/step - loss: 0.0389 - acc: 0.9846 - val_loss: 0.0407 - val_acc: 0.9841\n",
      "Epoch 32/32\n",
      "  2464/102124 [..............................] - ETA: 10:12 - loss: 0.0382 - acc: 0.9848 37792/102124 [==========>...................] - ETA: 6:30 - loss: 0.0391 - acc: 0.9842 75744/102124 [=====================>........] - ETA: 2:40 - loss: 0.0389 - acc: 0.9843102124/102124 [==============================] - 659s 6ms/step - loss: 0.0387 - acc: 0.9844 - val_loss: 0.0405 - val_acc: 0.9841\n",
      "roc-auc: 0.9933 - roc-auc_val: 0.9858                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "history = train_with_cv(model, batchSize=32, rocEvery = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3902,
     "status": "ok",
     "timestamp": 1530913091131,
     "user": {
      "displayName": "Deep Learning",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115257841230779963257"
     },
     "user_tz": -120
    },
    "id": "sms3R-U4469B",
    "outputId": "58413b93-886c-4fdb-af42-dd62b114c68b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAEVCAYAAAAyxLK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njpJZERERERERcTv/H/y/s+vBAeL+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4f42648860>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 103059,
     "status": "ok",
     "timestamp": 1530913194489,
     "user": {
      "displayName": "Deep Learning",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115257841230779963257"
     },
     "user_tz": -120
    },
    "id": "r2gtMBj2Tp9A",
    "outputId": "986d4af4-3ebd-4bd3-9c08-ff3810f7088d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31915/31915 [==============================] - 54s 2ms/step\n",
      "([0.0385048417558626, 0.9846675929820745], 0.9887902222753547)\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_on_test(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gDhVACYdjLfl"
   },
   "source": [
    "Medium batch size training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1414
    },
    "colab_type": "code",
    "id": "Z1TB8Nh0jIfn",
    "outputId": "c6b81f75-c4d7-4340-c3c0-2c9929949769"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 102124 samples, validate on 25532 samples\n",
      "Epoch 1/32\n",
      " 42816/102124 [===========>..................] - ETA: 5:05 - loss: 0.1709 - acc: 0.9300102124/102124 [==============================] - 548s 5ms/step - loss: 0.1138 - acc: 0.9556 - val_loss: 0.0701 - val_acc: 0.9792\n",
      "Epoch 2/32\n",
      "  5440/102124 [>.............................] - ETA: 7:55 - loss: 0.0658 - acc: 0.9763102080/102124 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9769102124/102124 [==============================] - 538s 5ms/step - loss: 0.0630 - acc: 0.9769 - val_loss: 0.0549 - val_acc: 0.9794\n",
      "roc-auc: 0.9763 - roc-auc_val: 0.9735                                                                                                    \n",
      "Epoch 3/32\n",
      "102124/102124 [==============================] - 543s 5ms/step - loss: 0.0565 - acc: 0.9789 - val_loss: 0.0527 - val_acc: 0.9808==>.] - ETA: 0s - loss: 0.0565 - acc: 0.978\n",
      "Epoch 4/32\n",
      " 20352/102124 [====>.........................] - ETA: 6:46 - loss: 0.0519 - acc: 0.9800102080/102124 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9804102124/102124 [==============================] - 543s 5ms/step - loss: 0.0524 - acc: 0.9804 - val_loss: 0.0638 - val_acc: 0.9801\n",
      "roc-auc: 0.9749 - roc-auc_val: 0.9677                                                                                                    \n",
      "Epoch 5/32\n",
      "102124/102124 [==============================] - 543s 5ms/step - loss: 0.0501 - acc: 0.9807 - val_loss: 0.0438 - val_acc: 0.9832==>.] - ETA: 0s - loss: 0.0501 - acc: 0.980\n",
      "Epoch 6/32\n",
      " 20352/102124 [====>.........................] - ETA: 6:45 - loss: 0.0476 - acc: 0.9817102080/102124 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9815102124/102124 [==============================] - 544s 5ms/step - loss: 0.0478 - acc: 0.9815 - val_loss: 0.0516 - val_acc: 0.9814\n",
      "roc-auc: 0.9854 - roc-auc_val: 0.9816                                                                                                    \n",
      "Epoch 7/32\n",
      "102124/102124 [==============================] - 543s 5ms/step - loss: 0.0468 - acc: 0.9818 - val_loss: 0.0466 - val_acc: 0.9829==>.] - ETA: 0s - loss: 0.0468 - acc: 0.981\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002679433673620224.\n",
      "Epoch 8/32\n",
      " 16064/102124 [===>..........................] - ETA: 7:01 - loss: 0.0457 - acc: 0.9824102080/102124 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9823102124/102124 [==============================] - 538s 5ms/step - loss: 0.0455 - acc: 0.9823 - val_loss: 0.0619 - val_acc: 0.9801\n",
      "roc-auc: 0.9863 - roc-auc_val: 0.9803                                                                                                    \n",
      "Epoch 9/32\n",
      "102124/102124 [==============================] - 537s 5ms/step - loss: 0.0444 - acc: 0.9826 - val_loss: 0.0462 - val_acc: 0.9832==>.] - ETA: 0s - loss: 0.0444 - acc: 0.982\n",
      "Epoch 10/32\n",
      " 20288/102124 [====>.........................] - ETA: 6:40 - loss: 0.0443 - acc: 0.9831102080/102124 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9830102124/102124 [==============================] - 536s 5ms/step - loss: 0.0436 - acc: 0.9830 - val_loss: 0.0446 - val_acc: 0.9831\n",
      "roc-auc: 0.9888 - roc-auc_val: 0.9848                                                                                                    \n",
      "Epoch 11/32\n",
      "102124/102124 [==============================] - 536s 5ms/step - loss: 0.0429 - acc: 0.9833 - val_loss: 0.0419 - val_acc: 0.9839==>.] - ETA: 0s - loss: 0.0429 - acc: 0.983\n",
      "Epoch 12/32\n",
      " 20288/102124 [====>.........................] - ETA: 6:39 - loss: 0.0396 - acc: 0.9840102080/102124 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9834102124/102124 [==============================] - 536s 5ms/step - loss: 0.0422 - acc: 0.9834 - val_loss: 0.0408 - val_acc: 0.9843\n",
      "roc-auc: 0.9925 - roc-auc_val: 0.9872                                                                                                    \n",
      "Epoch 13/32\n",
      "102124/102124 [==============================] - 535s 5ms/step - loss: 0.0415 - acc: 0.9836 - val_loss: 0.0403 - val_acc: 0.9844==>.] - ETA: 0s - loss: 0.0416 - acc: 0.983\n",
      "Epoch 14/32\n",
      " 20288/102124 [====>.........................] - ETA: 6:39 - loss: 0.0404 - acc: 0.9842102080/102124 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9839102124/102124 [==============================] - 535s 5ms/step - loss: 0.0406 - acc: 0.9839 - val_loss: 0.0410 - val_acc: 0.9842\n",
      "roc-auc: 0.9931 - roc-auc_val: 0.987                                                                                                    \n",
      "Epoch 15/32\n",
      "102124/102124 [==============================] - 534s 5ms/step - loss: 0.0403 - acc: 0.9841 - val_loss: 0.0446 - val_acc: 0.9837==>.] - ETA: 0s - loss: 0.0403 - acc: 0.984\n",
      "Epoch 16/32\n",
      " 20288/102124 [====>.........................] - ETA: 6:38 - loss: 0.0393 - acc: 0.9844102080/102124 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9841102124/102124 [==============================] - 535s 5ms/step - loss: 0.0399 - acc: 0.9841 - val_loss: 0.0409 - val_acc: 0.9843\n",
      "roc-auc: 0.9932 - roc-auc_val: 0.9871                                                                                                    \n",
      "Epoch 17/32\n",
      "102124/102124 [==============================] - 535s 5ms/step - loss: 0.0397 - acc: 0.9842 - val_loss: 0.0405 - val_acc: 0.9845==>.] - ETA: 0s - loss: 0.0397 - acc: 0.984\n",
      "Epoch 18/32\n",
      "102124/102124 [==============================] - 535s 5ms/step - loss: 0.0389 - acc: 0.9843 - val_loss: 0.0409 - val_acc: 0.9846==>.] - ETA: 0s - loss: 0.0389 - acc: 0.984\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 8.53775127325207e-05.\n",
      "roc-auc: 0.9941 - roc-auc_val: 0.9874                                                                                                    \n",
      "Epoch 19/32\n",
      "102124/102124 [==============================] - 534s 5ms/step - loss: 0.0384 - acc: 0.9844 - val_loss: 0.0403 - val_acc: 0.9849==>.] - ETA: 0s - loss: 0.0384 - acc: 0.984\n",
      "Epoch 20/32\n",
      " 20288/102124 [====>.........................] - ETA: 6:38 - loss: 0.0386 - acc: 0.9840102080/102124 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9845102124/102124 [==============================] - 534s 5ms/step - loss: 0.0381 - acc: 0.9845 - val_loss: 0.0401 - val_acc: 0.9846\n",
      "roc-auc: 0.9947 - roc-auc_val: 0.9878                                                                                                    \n",
      "Epoch 21/32\n",
      "102124/102124 [==============================] - 534s 5ms/step - loss: 0.0377 - acc: 0.9847 - val_loss: 0.0424 - val_acc: 0.9837==>.] - ETA: 0s - loss: 0.0377 - acc: 0.984\n",
      "Epoch 22/32\n",
      " 20288/102124 [====>.........................] - ETA: 6:39 - loss: 0.0376 - acc: 0.9846102080/102124 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9849102124/102124 [==============================] - 534s 5ms/step - loss: 0.0375 - acc: 0.9849 - val_loss: 0.0405 - val_acc: 0.9849\n",
      "roc-auc: 0.9952 - roc-auc_val: 0.987                                                                                                    \n",
      "Epoch 23/32\n",
      "102124/102124 [==============================] - 533s 5ms/step - loss: 0.0371 - acc: 0.9848 - val_loss: 0.0409 - val_acc: 0.9846==>.] - ETA: 0s - loss: 0.0371 - acc: 0.984\n",
      "Epoch 24/32\n",
      " 20288/102124 [====>.........................] - ETA: 6:38 - loss: 0.0359 - acc: 0.9855102080/102124 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9851102124/102124 [==============================] - 535s 5ms/step - loss: 0.0368 - acc: 0.9851 - val_loss: 0.0420 - val_acc: 0.9837\n",
      "roc-auc: 0.9946 - roc-auc_val: 0.9847                                                                                                    \n",
      "Epoch 25/32\n",
      "102124/102124 [==============================] - 534s 5ms/step - loss: 0.0365 - acc: 0.9850 - val_loss: 0.0405 - val_acc: 0.9847==>.] - ETA: 0s - loss: 0.0365 - acc: 0.985\n",
      "Epoch 26/32\n",
      " 20288/102124 [====>.........................] - ETA: 6:38 - loss: 0.0364 - acc: 0.9849102080/102124 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9852102124/102124 [==============================] - 534s 5ms/step - loss: 0.0363 - acc: 0.9852 - val_loss: 0.0407 - val_acc: 0.9848\n",
      "roc-auc: 0.9957 - roc-auc_val: 0.9867                                                                                                    \n",
      "Epoch 27/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102124/102124 [==============================] - 535s 5ms/step - loss: 0.0360 - acc: 0.9854 - val_loss: 0.0406 - val_acc: 0.9847==>.] - ETA: 0s - loss: 0.0360 - acc: 0.985\n",
      "Epoch 28/32\n",
      " 20288/102124 [====>.........................] - ETA: 6:39 - loss: 0.0354 - acc: 0.9855102080/102124 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9853102124/102124 [==============================] - 534s 5ms/step - loss: 0.0360 - acc: 0.9853 - val_loss: 0.0403 - val_acc: 0.9847\n",
      "roc-auc: 0.9958 - roc-auc_val: 0.9866                                                                                                    \n",
      "Epoch 29/32\n",
      "102124/102124 [==============================] - 533s 5ms/step - loss: 0.0356 - acc: 0.9852 - val_loss: 0.0409 - val_acc: 0.9848==>.] - ETA: 0s - loss: 0.0356 - acc: 0.985\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 2.7204705475014634e-05.\n",
      "Epoch 30/32\n",
      " 16000/102124 [===>..........................] - ETA: 6:59 - loss: 0.0355 - acc: 0.9854 23552/102124 [=====>........................] - ETA: 6:22 - loss: 0.0347 - acc: 0.9857"
     ]
    }
   ],
   "source": [
    "history = train_with_cv(model, batchSize=64, rocEvery = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SsCKGcVcjIke"
   },
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RPyypYJkjIpj"
   },
   "outputs": [],
   "source": [
    "print(evaluate_on_test(model))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "features_with_each_avg_64.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
