{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/gabrijel/anaconda3/envs/machine-learning/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from keras.preprocessing import text, sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "\n",
    "\n",
    "maxWords = 30000\n",
    "maxLengthInWords = 400\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    cleanedText = clean(text)\n",
    "    tokenizedText = itertools.islice(word_tokenize(cleanedText), maxLengthInWords)\n",
    "    withoutStopwords = removeStopwords(tokenizedText)\n",
    "    lemmatizedText = lemmatize(withoutStopwords)\n",
    "\n",
    "    return lemmatizedText\n",
    "\n",
    "def clean_and_save(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    \n",
    "    corpus_file = open('corpus-clean.txt', 'a')\n",
    "    corpus_file.write(text+'\\n')\n",
    "\n",
    "    return text\n",
    "\n",
    "def removeStopwords(words):\n",
    "    return [word for word in words if word not in stopwords.words('english')]\n",
    "\n",
    "def lemmatize(text):\n",
    "    for word, tag in pos_tag(text):\n",
    "        if tag.startswith(\"NN\"):\n",
    "            return lemmatizer.lemmatize(word, pos='n')\n",
    "        elif tag.startswith('VB'):\n",
    "            return lemmatizer.lemmatize(word, pos='v')\n",
    "        elif tag.startswith('JJ'):\n",
    "            return lemmatizer.lemmatize(word, pos='a')\n",
    "        elif tag.startswith('R'):\n",
    "            return lemmatizer.lemmatize(word, pos='r')\n",
    "        else:\n",
    "            return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "trainTestValData = pd.read_csv(os.getcwd() + '/train.csv')\n",
    "submissionData = pd.read_csv(os.getcwd() + '/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "trainTestValData['comment_text'].fillna('fillna', inplace=True)\n",
    "submissionData['comment_text'].fillna('fillna', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my username hardcore metallica fan were reverted they were not vandalisms just closure on some gas after i voted at new york dolls fac and please do not remove the template from the talk page since i am retired now 89 205 38 27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he matches this background colour i am seemingly stuck with thanks talk 21 51 january 11 2016 utc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i am really not trying to edit war it just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page he seems to care more about the formatting than the actual info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>more i cannot make any real suggestions on improvement i wondered if the section statistics should be later on or a subsection of types of accidents i think the references may need tidying so that they are all in the exact same format ie date format etc i can do that later on if no one else does first if you have any preferences for formatting style on references or want to do it yourself please let me know there appears to be a backlog on articles for review so i guess there may be a delay until a reviewer turns up it listed in the relevant form eg wikipedia good_article_nominations transport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember what page that on</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  \\\n",
       "0  0000997932d777bf   \n",
       "1  000103f0d9cfb60f   \n",
       "2  000113f07ec002fd   \n",
       "3  0001b41b1c6bb37e   \n",
       "4  0001d958c54c6e35   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         comment_text  \\\n",
       "0  Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27                                                                                                                                                                                                                                                                                                                                                                            \n",
       "1  D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "2  Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "3  \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"   \n",
       "4  You, sir, are my hero. Any chance you remember what page that's on?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "\n",
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0  0      0             0        0       0       0               \n",
       "1  0      0             0        0       0       0               \n",
       "2  0      0             0        0       0       0               \n",
       "3  0      0             0        0       0       0               \n",
       "4  0      0             0        0       0       0               \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          preprocessed_text  \n",
       "0  explanation why the edits made under my username hardcore metallica fan were reverted they were not vandalisms just closure on some gas after i voted at new york dolls fac and please do not remove the template from the talk page since i am retired now 89 205 38 27                                                                                                                                                                                                                                                                                                                                                  \n",
       "1  d aww he matches this background colour i am seemingly stuck with thanks talk 21 51 january 11 2016 utc                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "2  hey man i am really not trying to edit war it just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page he seems to care more about the formatting than the actual info                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "3  more i cannot make any real suggestions on improvement i wondered if the section statistics should be later on or a subsection of types of accidents i think the references may need tidying so that they are all in the exact same format ie date format etc i can do that later on if no one else does first if you have any preferences for formatting style on references or want to do it yourself please let me know there appears to be a backlog on articles for review so i guess there may be a delay until a reviewer turns up it listed in the relevant form eg wikipedia good_article_nominations transport  \n",
       "4  you sir are my hero any chance you remember what page that on                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainTestValData['preprocessed_text'] = trainTestValData['comment_text'].apply(clean_and_save)\n",
    "submissionData['preprocessed_text'] = submissionData['comment_text'].apply(clean_and_save)\n",
    "\n",
    "trainTestValData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_full = trainTestValData['preprocessed_text']\n",
    "y_train_full = trainTestValData[labels].values\n",
    "\n",
    "X_submission = submissionData['preprocessed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=maxWords)\n",
    "tokenizer.fit_on_texts(list(X_train_full) + list(X_submission))\n",
    "\n",
    "X_train_full = tokenizer.texts_to_sequences(X_train_full)\n",
    "X_submission = tokenizer.texts_to_sequences(X_submission)\n",
    "\n",
    "X_train_full = sequence.pad_sequences(X_train_full, maxlen=maxLengthInWords)\n",
    "X_submission = sequence.pad_sequences(X_submission, maxlen=maxLengthInWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct custom fasttext embeddings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(word, *embeddingVector): return word, np.asarray(embeddingVector, dtype='float32')\n",
    "\n",
    "fastTextEmbeddingsFile = os.getcwd() + '/toxic-embeddings.vec'\n",
    "fastTextEmbeddings = dict(parse(*wordEmbeddingPair.rstrip().rsplit(' ')) for wordEmbeddingPair in open(fastTextEmbeddingsFile))\n",
    "\n",
    "tokenizerDictionary = tokenizer.word_index\n",
    "\n",
    "wordsNumber = min(maxWords, len(tokenizerDictionary))\n",
    "fastTextEmbeddingsMatrix = np.zeros((wordsNumber, 300))\n",
    "\n",
    "for word, i in tokenizerDictionary.items():\n",
    "    if i >= wordsNumber: \n",
    "        break \n",
    "        \n",
    "    embeddingVector = fastTextEmbeddings.get(word)\n",
    "    \n",
    "    if embeddingVector is not None: \n",
    "        fastTextEmbeddingsMatrix[i] = embeddingVector\n",
    "        \n",
    "np.save('custom_fast_text_embeddings.npy', fastTextEmbeddingsMatrix)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct pretrained fasttext embeddings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(word, *embeddingVector): return word, np.asarray(embeddingVector, dtype='float32')\n",
    "\n",
    "fastTextEmbeddingsFile = os.getcwd() + '/crawl-300d-2M.vec'\n",
    "fastTextEmbeddings = dict(parse(*wordEmbeddingPair.rstrip().rsplit(' ')) for wordEmbeddingPair in open(fastTextEmbeddingsFile))\n",
    "\n",
    "tokenizerDictionary = tokenizer.word_index\n",
    "\n",
    "wordsNumber = min(maxWords, len(tokenizerDictionary))\n",
    "fastTextEmbeddingsMatrix = np.zeros((wordsNumber, 300))\n",
    "\n",
    "for word, i in tokenizerDictionary.items():\n",
    "    if i >= wordsNumber: \n",
    "        break \n",
    "        \n",
    "    embeddingVector = fastTextEmbeddings.get(word)\n",
    "    \n",
    "    if embeddingVector is not None: \n",
    "        fastTextEmbeddingsMatrix[i] = embeddingVector\n",
    "        \n",
    "np.save('fast_text_embeddings.npy', fastTextEmbeddingsMatrix)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDatasetSplits(maxWords = 30000, maxSequenceLengthInWords = 400):\n",
    "    \n",
    "    global X_train_full\n",
    "    global y_train_full\n",
    "    global X_submission\n",
    "    \n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X_train_full, y_train_full, train_size=0.8, random_state=256)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, train_size=0.8, random_state=256)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_train_full, y_train_full, X_submission\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test, X_train_full, y_train_full, X_submission = getDatasetSplits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('X_train.npy', X_train)\n",
    "np.save('X_val.npy', X_val)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('X_train_full.npy', X_train_full)\n",
    "\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('y_val.npy', y_val)\n",
    "np.save('y_test.npy', y_test)\n",
    "np.save('y_train_full.npy', y_train_full)\n",
    "\n",
    "np.save('X_submission.npy', X_submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
