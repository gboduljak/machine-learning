{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gru_with_yoon_kim_3.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "yS1FnhiWX3Js",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "46fea712-a411-48ad-8576-efa2fcfa1740",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525250883032,
          "user_tz": -120,
          "elapsed": 11240,
          "user": {
            "displayName": "Deep Learning",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110970714976109420834"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install keras\n",
        "!pip install sklearn\n",
        "!pip install matplotlib\n",
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.1.6)\r\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.12)\r\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (0.19.1)\r\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.3)\r\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\r\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.7.1)\n",
            "Collecting sklearn\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.19.1)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Running setup.py bdist_wheel for sklearn ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (2.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2018.4)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.14.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xlKzkDJFrjA-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5acff8b-738b-4b36-ae37-e0eaaa256c19",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525250890717,
          "user_tz": -120,
          "elapsed": 7642,
          "user": {
            "displayName": "Deep Learning",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110970714976109420834"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "K.clear_session()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "eQEKwl4oAxO7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "cfg = K.tf.ConfigProto()\n",
        "cfg.gpu_options.allow_growth = True\n",
        "K.set_session(K.tf.Session(config=cfg))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "12M0egCCX-27",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4lN2WTUEYBYv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "file_import = drive.CreateFile({'id':'1p1bsltfTcIrZ_kfE6kwGTPzcdXorHbb2'})\n",
        "file_import.GetContentFile('colab_setup.py') \n",
        "from colab_setup import setup\n",
        "\n",
        "setup(drive)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cHBlD0tVj2TY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "460906ca-a7ec-45d3-9cdb-4a34881ed294",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525250932196,
          "user_tz": -120,
          "elapsed": 1571,
          "user": {
            "displayName": "Deep Learning",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110970714976109420834"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "colab_setup.py\t\t\t roc_auc_callback.py\tX_train.npy\r\n",
            "custom_fast_text_embeddings.npy  sample_submission.csv\tX_val.npy\r\n",
            "datalab\t\t\t\t train_model.py\t\ty_test.npy\r\n",
            "fast_text_embeddings.npy\t X_submission.npy\ty_train_full.npy\r\n",
            "plot_history.py\t\t\t X_test.npy\t\ty_train.npy\r\n",
            "__pycache__\t\t\t X_train_full.npy\ty_val.npy\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yMwWPTMYXyno",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from plot_history import plot_history\n",
        "from roc_auc_callback import RocAucCallback\n",
        "from train_model import train_with_cv, train_with_submitting, evaluate_on_test\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from keras.layers.merge import concatenate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MIWjPi9bs5d4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def yoon_kim_conv_layer(filtersNumber, inputLayer):\n",
        "    block_1_conv_1 = Conv1D(filtersNumber, 1, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(inputLayer)\n",
        "    block_1_batchnorm1 = BatchNormalization()(block_1_conv_1)\n",
        "    block_1_max_pool1 = MaxPooling1D()(block_1_batchnorm1)\n",
        "    \n",
        "    block_1_conv_2 = Conv1D(filtersNumber, 2, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(inputLayer)\n",
        "    block_1_batchnorm2 = BatchNormalization()(block_1_conv_2)\n",
        "    block_1_max_pool2 = MaxPooling1D()(block_1_batchnorm2)\n",
        "\n",
        "    block_1_conv_3 = Conv1D(filtersNumber, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(inputLayer)\n",
        "    block_1_batchnorm3 = BatchNormalization()(block_1_conv_3)\n",
        "    block_1_max_pool3 = MaxPooling1D()(block_1_batchnorm3)\n",
        "\n",
        "    block_1_conv_4 = Conv1D(filtersNumber, 5, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(inputLayer)\n",
        "    block_1_batchnorm4 = BatchNormalization()(block_1_conv_4)\n",
        "    block_1_max_pool4 = MaxPooling1D()(block_1_batchnorm4)\n",
        "\n",
        "    block_1_features = concatenate([block_1_max_pool1, block_1_max_pool2, block_1_max_pool3, block_1_max_pool4])\n",
        "    block_1_features = Dropout(0.2)(block_1_features)\n",
        "    \n",
        "    return block_1_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LTFG7OgsXynw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 2961
        },
        "outputId": "0ad20484-734d-4e82-a7ed-0109afcae7a9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525250937576,
          "user_tz": -120,
          "elapsed": 4133,
          "user": {
            "displayName": "Deep Learning",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110970714976109420834"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "maxWords = 30000\n",
        "maxSequenceLengthInWords = 400\n",
        "embeddingDimension = 300\n",
        "filtersNumber = 64\n",
        "\n",
        "input_layer = Input(shape=(maxSequenceLengthInWords,))\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    maxWords, \n",
        "    output_dim=embeddingDimension, \n",
        "    input_length=maxSequenceLengthInWords,\n",
        "    weights = [np.load('fast_text_embeddings.npy')],\n",
        "    trainable = False\n",
        ")(input_layer)\n",
        "embedding_dropout = SpatialDropout1D(0.2)(embedding_layer)\n",
        "\n",
        "bidirectional = Bidirectional(GRU(150, dropout = 0.2, recurrent_dropout = 0.2, return_sequences=True))(embedding_dropout)\n",
        "bidirectional_normalization = BatchNormalization()(bidirectional)\n",
        "bidirectional_dropout = SpatialDropout1D(0.2)(bidirectional_normalization)\n",
        "bidirectional_avg_pool = GlobalAveragePooling1D()(bidirectional_normalization)\n",
        "bidirectional_max_pool = GlobalMaxPooling1D()(bidirectional_normalization)\n",
        "bidirectional_gru_outs = concatenate([bidirectional_avg_pool, bidirectional_max_pool])\n",
        "\n",
        "block_1_features = yoon_kim_conv_layer(filtersNumber, bidirectional_dropout)\n",
        "block_2_features = yoon_kim_conv_layer(filtersNumber * 2, block_1_features)\n",
        "block_3_features = yoon_kim_conv_layer(filtersNumber * 4, block_2_features)\n",
        "\n",
        "block_4_conv_1 = Conv1D(filtersNumber * 8, 1, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(block_3_features)\n",
        "block_4_batchnorm1 = BatchNormalization()(block_4_conv_1)\n",
        "block_4_max_pool1 = GlobalMaxPooling1D()(block_4_batchnorm1)\n",
        "\n",
        "block_4_conv_2 = Conv1D(filtersNumber * 8, 2, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(block_3_features)\n",
        "block_4_batchnorm2 = BatchNormalization()(block_4_conv_2)\n",
        "block_4_max_pool2 = GlobalMaxPooling1D()(block_4_batchnorm2)\n",
        "\n",
        "block_4_conv_3 = Conv1D(filtersNumber * 8, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(block_3_features)\n",
        "block_4_batchnorm3 = BatchNormalization()(block_4_conv_3)\n",
        "block_4_max_pool3 = GlobalMaxPooling1D()(block_4_batchnorm3)\n",
        "\n",
        "block_4_conv_4 = Conv1D(filtersNumber * 8, 5, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(block_3_features)\n",
        "block_4_batchnorm4 = BatchNormalization()(block_4_conv_4)\n",
        "block_4_max_pool4 = GlobalMaxPooling1D()(block_4_batchnorm4)\n",
        "\n",
        "block_4_features = concatenate([block_4_max_pool1, block_4_max_pool2, block_4_max_pool3, block_4_max_pool4])\n",
        "block_4_features = Dropout(0.2)(block_4_features)\n",
        "\n",
        "features = concatenate([block_4_features, bidirectional_gru_outs])\n",
        "features_dropout = Dropout(0.2)(features)\n",
        "\n",
        "dense_1 = Dense(256, activation = 'elu')(features_dropout)\n",
        "dense_1_normalization = BatchNormalization()(dense_1)\n",
        "dense_1_dropout = Dropout(0.2)(dense_1_normalization)\n",
        "\n",
        "dense_2 = Dense(256, activation = 'elu')(dense_1_dropout)\n",
        "dense_2_normalization = BatchNormalization()(dense_2)\n",
        "dense_2_dropout = Dropout(0.2)(dense_2_normalization)\n",
        "\n",
        "output_layer = Dense(6, activation='sigmoid')(dense_2_dropout)\n",
        "\n",
        "model = Model(inputs=[input_layer], outputs=[output_layer])\n",
        "            \n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy', \n",
        "    optimizer='Adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`NHWC` for data_format is deprecated, use `NWC` instead\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 400)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 400, 300)     9000000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_1 (SpatialDro (None, 400, 300)     0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 400, 300)     405900      spatial_dropout1d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 400, 300)     1200        bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_2 (SpatialDro (None, 400, 300)     0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 400, 64)      19264       spatial_dropout1d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 400, 64)      38464       spatial_dropout1d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 400, 64)      57664       spatial_dropout1d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 400, 64)      96064       spatial_dropout1d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 400, 64)      256         conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 400, 64)      256         conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 400, 64)      256         conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 400, 64)      256         conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 200, 64)      0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, 200, 64)      0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, 200, 64)      0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1D)  (None, 200, 64)      0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 200, 256)     0           max_pooling1d_1[0][0]            \n",
            "                                                                 max_pooling1d_2[0][0]            \n",
            "                                                                 max_pooling1d_3[0][0]            \n",
            "                                                                 max_pooling1d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 200, 256)     0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 200, 128)     32896       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 200, 128)     65664       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 200, 128)     98432       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 200, 128)     163968      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 200, 128)     512         conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 200, 128)     512         conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 200, 128)     512         conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 200, 128)     512         conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1D)  (None, 100, 128)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1D)  (None, 100, 128)     0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1D)  (None, 100, 128)     0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1D)  (None, 100, 128)     0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 100, 512)     0           max_pooling1d_5[0][0]            \n",
            "                                                                 max_pooling1d_6[0][0]            \n",
            "                                                                 max_pooling1d_7[0][0]            \n",
            "                                                                 max_pooling1d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 100, 512)     0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_9 (Conv1D)               (None, 100, 256)     131328      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_10 (Conv1D)              (None, 100, 256)     262400      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_11 (Conv1D)              (None, 100, 256)     393472      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_12 (Conv1D)              (None, 100, 256)     655616      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 100, 256)     1024        conv1d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 100, 256)     1024        conv1d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 100, 256)     1024        conv1d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 100, 256)     1024        conv1d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_9 (MaxPooling1D)  (None, 50, 256)      0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling1D) (None, 50, 256)      0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_11 (MaxPooling1D) (None, 50, 256)      0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_12 (MaxPooling1D) (None, 50, 256)      0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 50, 1024)     0           max_pooling1d_9[0][0]            \n",
            "                                                                 max_pooling1d_10[0][0]           \n",
            "                                                                 max_pooling1d_11[0][0]           \n",
            "                                                                 max_pooling1d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 50, 1024)     0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_13 (Conv1D)              (None, 50, 512)      524800      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_14 (Conv1D)              (None, 50, 512)      1049088     dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_15 (Conv1D)              (None, 50, 512)      1573376     dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_16 (Conv1D)              (None, 50, 512)      2621952     dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 50, 512)      2048        conv1d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 50, 512)      2048        conv1d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 50, 512)      2048        conv1d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 50, 512)      2048        conv1d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 512)          0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_3 (GlobalM (None, 512)          0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_4 (GlobalM (None, 512)          0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_5 (GlobalM (None, 512)          0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 2048)         0           global_max_pooling1d_2[0][0]     \n",
            "                                                                 global_max_pooling1d_3[0][0]     \n",
            "                                                                 global_max_pooling1d_4[0][0]     \n",
            "                                                                 global_max_pooling1d_5[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_1 (Glo (None, 300)          0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 300)          0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 2048)         0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 600)          0           global_average_pooling1d_1[0][0] \n",
            "                                                                 global_max_pooling1d_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 2648)         0           dropout_4[0][0]                  \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 2648)         0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          678144      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 256)          1024        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 256)          0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 256)          65792       dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 256)          1024        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 256)          0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 6)            1542        dropout_7[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 17,954,434\n",
            "Trainable params: 8,945,130\n",
            "Non-trainable params: 9,009,304\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xwMmTewgXynz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "d588b713-c983-4354-fcd7-2b3556442d6d"
      },
      "cell_type": "code",
      "source": [
        "history = train_with_cv(model, batchSize=64, rocEvery = 2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 102124 samples, validate on 25532 samples\n",
            "Epoch 1/32\n",
            " 42624/102124 [===========>..................] - ETA: 29:31 - loss: 0.1633 - acc: 0.9390"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102124/102124 [==============================] - 3233s 32ms/step - loss: 0.1030 - acc: 0.9621 - val_loss: 0.0554 - val_acc: 0.9785\n",
            "Epoch 2/32\n",
            "  5056/102124 [>.............................] - ETA: 47:58 - loss: 0.0541 - acc: 0.9807"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0535 - acc: 0.9803"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102124/102124 [==============================] - 3235s 32ms/step - loss: 0.0535 - acc: 0.9803 - val_loss: 0.0451 - val_acc: 0.9832\n",
            "roc-auc: 0.9794 - roc-auc_val: 0.9793                                                                                                    \n",
            "Epoch 3/32\n",
            " 17280/102124 [====>.........................] - ETA: 42:22 - loss: 0.0498 - acc: 0.9811"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0491 - acc: 0.9815"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r102124/102124 [==============================] - 3257s 32ms/step - loss: 0.0490 - acc: 0.9815 - val_loss: 0.0425 - val_acc: 0.9838\n",
            "Epoch 4/32\n",
            " 20160/102124 [====>.........................] - ETA: 40:31 - loss: 0.0452 - acc: 0.9827"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0465 - acc: 0.9824"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102124/102124 [==============================] - 3229s 32ms/step - loss: 0.0465 - acc: 0.9824 - val_loss: 0.0410 - val_acc: 0.9843\n",
            "roc-auc: 0.9886 - roc-auc_val: 0.9853                                                                                                    \n",
            "Epoch 5/32\n",
            " 17280/102124 [====>.........................] - ETA: 41:55 - loss: 0.0447 - acc: 0.9830"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0449 - acc: 0.9827"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r102124/102124 [==============================] - 3260s 32ms/step - loss: 0.0449 - acc: 0.9827 - val_loss: 0.0404 - val_acc: 0.9844\n",
            "Epoch 6/32\n",
            " 20160/102124 [====>.........................] - ETA: 41:20 - loss: 0.0434 - acc: 0.9830"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0431 - acc: 0.9833"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102124/102124 [==============================] - 3253s 32ms/step - loss: 0.0431 - acc: 0.9833 - val_loss: 0.0406 - val_acc: 0.9845\n",
            "roc-auc: 0.9896 - roc-auc_val: 0.9869                                                                                                    \n",
            "Epoch 7/32\n",
            " 17280/102124 [====>.........................] - ETA: 42:12 - loss: 0.0407 - acc: 0.9839"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0419 - acc: 0.9835"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r102124/102124 [==============================] - 3252s 32ms/step - loss: 0.0419 - acc: 0.9835 - val_loss: 0.0394 - val_acc: 0.9844\n",
            "Epoch 8/32\n",
            " 20160/102124 [====>.........................] - ETA: 40:39 - loss: 0.0405 - acc: 0.9841"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0403 - acc: 0.9841"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102124/102124 [==============================] - 3245s 32ms/step - loss: 0.0403 - acc: 0.9841 - val_loss: 0.0414 - val_acc: 0.9843\n",
            "roc-auc: 0.9923 - roc-auc_val: 0.9853                                                                                                    \n",
            "Epoch 9/32\n",
            " 17280/102124 [====>.........................] - ETA: 41:38 - loss: 0.0380 - acc: 0.9849"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0390 - acc: 0.9844"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r102124/102124 [==============================] - 3225s 32ms/step - loss: 0.0390 - acc: 0.9844 - val_loss: 0.0417 - val_acc: 0.9845\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00021763764380011708.\n",
            "Epoch 10/32\n",
            " 15872/102124 [===>..........................] - ETA: 42:33 - loss: 0.0394 - acc: 0.9841"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0386 - acc: 0.9846"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102124/102124 [==============================] - 3244s 32ms/step - loss: 0.0386 - acc: 0.9846 - val_loss: 0.0407 - val_acc: 0.9845\n",
            "roc-auc: 0.9918 - roc-auc_val: 0.9874                                                                                                    \n",
            "Epoch 11/32\n",
            " 17216/102124 [====>.........................] - ETA: 42:07 - loss: 0.0371 - acc: 0.9849"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43712/102124 [===========>..................] - ETA: 28:57 - loss: 0.0373 - acc: 0.9848"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oAHPajaB6fkY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# It seems like model is best to fit in the interval of 8 to 12 epochs.\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "sms3R-U4469B",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r2gtMBj2Tp9A",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(evaluate_on_test(model))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}