{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gru_with_yoon_kim_4.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "yS1FnhiWX3Js",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "469e62a8-3bc5-4ec3-b74b-a4cc6fecb2c0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525250934706,
          "user_tz": -120,
          "elapsed": 11307,
          "user": {
            "displayName": "Deep Learner",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102934620980301123540"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install keras\n",
        "!pip install sklearn\n",
        "!pip install matplotlib\n",
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.1.6)\r\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.12)\r\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (0.19.1)\r\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.3)\r\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\r\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.7.1)\n",
            "Collecting sklearn\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.19.1)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Running setup.py bdist_wheel for sklearn ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (2.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.14.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.11.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2018.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xlKzkDJFrjA-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c63f7dfd-3e1e-418e-e6c8-39ec101ae2c8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525250942372,
          "user_tz": -120,
          "elapsed": 7626,
          "user": {
            "displayName": "Deep Learner",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102934620980301123540"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "K.clear_session()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "eQEKwl4oAxO7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "cfg = K.tf.ConfigProto()\n",
        "cfg.gpu_options.allow_growth = True\n",
        "K.set_session(K.tf.Session(config=cfg))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "12M0egCCX-27",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4lN2WTUEYBYv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "file_import = drive.CreateFile({'id':'1p1bsltfTcIrZ_kfE6kwGTPzcdXorHbb2'})\n",
        "file_import.GetContentFile('colab_setup.py') \n",
        "from colab_setup import setup\n",
        "\n",
        "setup(drive)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cHBlD0tVj2TY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d5d3e7a3-ed54-4ec0-edf6-44456deb3346",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525250987560,
          "user_tz": -120,
          "elapsed": 1534,
          "user": {
            "displayName": "Deep Learner",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102934620980301123540"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "colab_setup.py\t\t\t roc_auc_callback.py\tX_train.npy\r\n",
            "custom_fast_text_embeddings.npy  sample_submission.csv\tX_val.npy\r\n",
            "datalab\t\t\t\t train_model.py\t\ty_test.npy\r\n",
            "fast_text_embeddings.npy\t X_submission.npy\ty_train_full.npy\r\n",
            "plot_history.py\t\t\t X_test.npy\t\ty_train.npy\r\n",
            "__pycache__\t\t\t X_train_full.npy\ty_val.npy\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yMwWPTMYXyno",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from plot_history import plot_history\n",
        "from roc_auc_callback import RocAucCallback\n",
        "from train_model import train_with_cv, train_with_submitting, evaluate_on_test\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from keras.layers.merge import concatenate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sQp1MgLkswXR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def yoon_kim_conv_layer(filtersNumber, inputLayer):\n",
        "    block_1_conv_1 = Conv1D(filtersNumber, 1, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(inputLayer)\n",
        "    block_1_batchnorm1 = BatchNormalization()(block_1_conv_1)\n",
        "    block_1_max_pool1 = MaxPooling1D()(block_1_batchnorm1)\n",
        "    \n",
        "    block_1_conv_2 = Conv1D(filtersNumber, 2, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(inputLayer)\n",
        "    block_1_batchnorm2 = BatchNormalization()(block_1_conv_2)\n",
        "    block_1_max_pool2 = MaxPooling1D()(block_1_batchnorm2)\n",
        "\n",
        "    block_1_conv_3 = Conv1D(filtersNumber, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(inputLayer)\n",
        "    block_1_batchnorm3 = BatchNormalization()(block_1_conv_3)\n",
        "    block_1_max_pool3 = MaxPooling1D()(block_1_batchnorm3)\n",
        "\n",
        "    block_1_conv_4 = Conv1D(filtersNumber, 5, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(inputLayer)\n",
        "    block_1_batchnorm4 = BatchNormalization()(block_1_conv_4)\n",
        "    block_1_max_pool4 = MaxPooling1D()(block_1_batchnorm4)\n",
        "\n",
        "    block_1_features = concatenate([block_1_max_pool1, block_1_max_pool2, block_1_max_pool3, block_1_max_pool4])\n",
        "    block_1_features = Dropout(0.2)(block_1_features)\n",
        "    block_1_features = Conv1D(300, 1, activation = 'elu', padding = 'valid', kernel_initializer = 'he_uniform')(inputLayer)\n",
        "    block_1_features = BatchNormalization()(block_1_features)\n",
        "    block_1_features = SpatialDropout1D(0.2)(block_1_features)\n",
        "    \n",
        "    return block_1_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LTFG7OgsXynw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1635
        },
        "outputId": "a38af6b5-4dc2-402f-c9af-bd7815f88337",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525250993288,
          "user_tz": -120,
          "elapsed": 4510,
          "user": {
            "displayName": "Deep Learner",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102934620980301123540"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "maxWords = 30000\n",
        "maxSequenceLengthInWords = 400\n",
        "embeddingDimension = 300\n",
        "filtersNumber = 64\n",
        "\n",
        "input_layer = Input(shape=(maxSequenceLengthInWords,))\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    maxWords, \n",
        "    output_dim=embeddingDimension, \n",
        "    input_length=maxSequenceLengthInWords,\n",
        "    weights = [np.load('fast_text_embeddings.npy')],\n",
        "    trainable = False\n",
        ")(input_layer)\n",
        "embedding_dropout = SpatialDropout1D(0.2)(embedding_layer)\n",
        "\n",
        "bidirectional = Bidirectional(GRU(150, dropout = 0.2, recurrent_dropout = 0.2, return_sequences=True))(embedding_dropout)\n",
        "bidirectional_normalization = BatchNormalization()(bidirectional)\n",
        "bidirectional_dropout = SpatialDropout1D(0.2)(bidirectional_normalization)\n",
        "bidirectional_avg_pool = GlobalAveragePooling1D()(bidirectional_normalization)\n",
        "bidirectional_max_pool = GlobalMaxPooling1D()(bidirectional_normalization)\n",
        "bidirectional_gru_outs = concatenate([bidirectional_avg_pool, bidirectional_max_pool])\n",
        "\n",
        "block_1_features = yoon_kim_conv_layer(filtersNumber, bidirectional_dropout)\n",
        "block_1_features = Add()([block_1_features, bidirectional_dropout])\n",
        "block_2_features = yoon_kim_conv_layer(filtersNumber * 2, block_1_features)\n",
        "block_2_features = Add()([block_2_features, block_1_features])\n",
        "block_3_features = yoon_kim_conv_layer(filtersNumber * 4, block_2_features)\n",
        "block_3_features = Add()([block_3_features, block_2_features])\n",
        "\n",
        "block_4_conv_1 = Conv1D(filtersNumber * 8, 1, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(block_3_features)\n",
        "block_4_batchnorm1 = BatchNormalization()(block_4_conv_1)\n",
        "block_4_max_pool1 = GlobalMaxPooling1D()(block_4_batchnorm1)\n",
        "block_4_avg_pool1 = GlobalAveragePooling1D()(block_4_batchnorm1)\n",
        "\n",
        "block_4_conv_2 = Conv1D(filtersNumber * 8, 2, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(block_3_features)\n",
        "block_4_batchnorm2 = BatchNormalization()(block_4_conv_2)\n",
        "block_4_max_pool2 = GlobalMaxPooling1D()(block_4_batchnorm2)\n",
        "block_4_avg_pool2 = GlobalAveragePooling1D()(block_4_batchnorm2)\n",
        "\n",
        "block_4_conv_3 = Conv1D(filtersNumber * 8, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(block_3_features)\n",
        "block_4_batchnorm3 = BatchNormalization()(block_4_conv_3)\n",
        "block_4_max_pool3 = GlobalMaxPooling1D()(block_4_batchnorm3)\n",
        "block_4_avg_pool3 = GlobalAveragePooling1D()(block_4_batchnorm3)\n",
        "\n",
        "block_4_conv_4 = Conv1D(filtersNumber * 8, 5, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(block_3_features)\n",
        "block_4_batchnorm4 = BatchNormalization()(block_4_conv_4)\n",
        "block_4_max_pool4 = GlobalMaxPooling1D()(block_4_batchnorm4)\n",
        "block_4_avg_pool4 = GlobalAveragePooling1D()(block_4_batchnorm4)\n",
        "\n",
        "block_4_features = concatenate([\n",
        "    block_4_max_pool1, \n",
        "    block_4_max_pool2, \n",
        "    block_4_max_pool3, \n",
        "    block_4_max_pool4\n",
        "])\n",
        "block_4_features = Dropout(0.2)(block_4_features)\n",
        "\n",
        "dense_1 = Dense(256, activation = 'elu')(block_4_features)\n",
        "dense_1_normalization = BatchNormalization()(dense_1)\n",
        "dense_1_dropout = Dropout(0.2)(dense_1_normalization)\n",
        "\n",
        "dense_2 = Dense(256, activation = 'elu')(dense_1_dropout)\n",
        "dense_2_normalization = BatchNormalization()(dense_2)\n",
        "dense_2_dropout = Dropout(0.2)(dense_2_normalization)\n",
        "\n",
        "output_layer = Dense(6, activation='sigmoid')(dense_2_dropout)\n",
        "\n",
        "model = Model(inputs=[input_layer], outputs=[output_layer])\n",
        "            \n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy', \n",
        "    optimizer='Adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`NHWC` for data_format is deprecated, use `NWC` instead\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 400)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 400, 300)     9000000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_1 (SpatialDro (None, 400, 300)     0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 400, 300)     405900      spatial_dropout1d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 400, 300)     1200        bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_2 (SpatialDro (None, 400, 300)     0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 400, 300)     90300       spatial_dropout1d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 400, 300)     1200        conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_3 (SpatialDro (None, 400, 300)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 400, 300)     0           spatial_dropout1d_3[0][0]        \n",
            "                                                                 spatial_dropout1d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_10 (Conv1D)              (None, 400, 300)     90300       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 400, 300)     1200        conv1d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_4 (SpatialDro (None, 400, 300)     0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 400, 300)     0           spatial_dropout1d_4[0][0]        \n",
            "                                                                 add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_15 (Conv1D)              (None, 400, 300)     90300       add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 400, 300)     1200        conv1d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_5 (SpatialDro (None, 400, 300)     0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 400, 300)     0           spatial_dropout1d_5[0][0]        \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_16 (Conv1D)              (None, 400, 512)     154112      add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_17 (Conv1D)              (None, 400, 512)     307712      add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_18 (Conv1D)              (None, 400, 512)     461312      add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_19 (Conv1D)              (None, 400, 512)     768512      add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 400, 512)     2048        conv1d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 400, 512)     2048        conv1d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 400, 512)     2048        conv1d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 400, 512)     2048        conv1d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 512)          0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_3 (GlobalM (None, 512)          0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_4 (GlobalM (None, 512)          0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_5 (GlobalM (None, 512)          0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 2048)         0           global_max_pooling1d_2[0][0]     \n",
            "                                                                 global_max_pooling1d_3[0][0]     \n",
            "                                                                 global_max_pooling1d_4[0][0]     \n",
            "                                                                 global_max_pooling1d_5[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 2048)         0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          524544      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 256)          1024        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 256)          0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 256)          65792       dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 256)          1024        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 256)          0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 6)            1542        dropout_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 11,975,366\n",
            "Trainable params: 2,967,846\n",
            "Non-trainable params: 9,007,520\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xwMmTewgXynz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "08cb1341-45c1-4033-c103-567f29e8dad1"
      },
      "cell_type": "code",
      "source": [
        "history = train_with_cv(model, batchSize = 64, rocEvery = 2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 102124 samples, validate on 25532 samples\n",
            "Epoch 1/32\n",
            " 42624/102124 [===========>..................] - ETA: 30:06 - loss: 0.1639 - acc: 0.9396"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102124/102124 [==============================] - 3289s 32ms/step - loss: 0.1033 - acc: 0.9625 - val_loss: 0.0488 - val_acc: 0.9818\n",
            "Epoch 2/32\n",
            "  5056/102124 [>.............................] - ETA: 48:36 - loss: 0.0578 - acc: 0.9797"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0531 - acc: 0.9804"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102124/102124 [==============================] - 3284s 32ms/step - loss: 0.0531 - acc: 0.9804 - val_loss: 0.0442 - val_acc: 0.9833\n",
            "roc-auc: 0.9832 - roc-auc_val: 0.9816                                                                                                    \n",
            "Epoch 3/32\n",
            " 17280/102124 [====>.........................] - ETA: 42:42 - loss: 0.0485 - acc: 0.9822"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0492 - acc: 0.9815"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r102124/102124 [==============================] - 3289s 32ms/step - loss: 0.0492 - acc: 0.9815 - val_loss: 0.0428 - val_acc: 0.9838\n",
            "Epoch 4/32\n",
            " 20160/102124 [====>.........................] - ETA: 41:37 - loss: 0.0461 - acc: 0.9828"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0469 - acc: 0.9822"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102124/102124 [==============================] - 3334s 33ms/step - loss: 0.0468 - acc: 0.9822 - val_loss: 0.0429 - val_acc: 0.9838\n",
            "roc-auc: 0.9873 - roc-auc_val: 0.984                                                                                                    \n",
            "Epoch 5/32\n",
            " 17344/102124 [====>.........................] - ETA: 43:42 - loss: 0.0453 - acc: 0.9831"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0448 - acc: 0.9827"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r102124/102124 [==============================] - 3341s 33ms/step - loss: 0.0448 - acc: 0.9827 - val_loss: 0.0406 - val_acc: 0.9842\n",
            "Epoch 6/32\n",
            " 20160/102124 [====>.........................] - ETA: 41:31 - loss: 0.0416 - acc: 0.9838"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0423 - acc: 0.9835"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102124/102124 [==============================] - 3318s 32ms/step - loss: 0.0423 - acc: 0.9835 - val_loss: 0.0403 - val_acc: 0.9845\n",
            "roc-auc: 0.9919 - roc-auc_val: 0.9883                                                                                                    \n",
            "Epoch 7/32\n",
            " 17280/102124 [====>.........................] - ETA: 42:51 - loss: 0.0393 - acc: 0.9848"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0412 - acc: 0.9839"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r102124/102124 [==============================] - 3303s 32ms/step - loss: 0.0412 - acc: 0.9839 - val_loss: 0.0396 - val_acc: 0.9847\n",
            "Epoch 8/32\n",
            " 20160/102124 [====>.........................] - ETA: 41:35 - loss: 0.0397 - acc: 0.9843"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0399 - acc: 0.9842"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102124/102124 [==============================] - 3336s 33ms/step - loss: 0.0399 - acc: 0.9842 - val_loss: 0.0419 - val_acc: 0.9833\n",
            "roc-auc: 0.9933 - roc-auc_val: 0.9883                                                                                                    \n",
            "Epoch 9/32\n",
            " 17280/102124 [====>.........................] - ETA: 42:47 - loss: 0.0394 - acc: 0.9847"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0386 - acc: 0.9846"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r102124/102124 [==============================] - 3312s 32ms/step - loss: 0.0386 - acc: 0.9846 - val_loss: 0.0401 - val_acc: 0.9845\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00021763764380011708.\n",
            "Epoch 10/32\n",
            " 15872/102124 [===>..........................] - ETA: 42:52 - loss: 0.0374 - acc: 0.9851"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0376 - acc: 0.9850"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102124/102124 [==============================] - 3241s 32ms/step - loss: 0.0376 - acc: 0.9850 - val_loss: 0.0398 - val_acc: 0.9847\n",
            "roc-auc: 0.9939 - roc-auc_val: 0.9881                                                                                                    \n",
            "Epoch 11/32\n",
            " 17216/102124 [====>.........................] - ETA: 41:56 - loss: 0.0358 - acc: 0.9855"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 22528/102124 [=====>........................] - ETA: 39:20 - loss: 0.0351 - acc: 0.9857"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oAHPajaB6fkY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# It seems like model is best to fit in the interval of 8 to 12 epochs.\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "sms3R-U4469B",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r2gtMBj2Tp9A",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(evaluate_on_test(model))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}