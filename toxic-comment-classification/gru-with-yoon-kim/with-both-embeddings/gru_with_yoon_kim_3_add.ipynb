{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gru_with_yoon_kim_3.add.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "yS1FnhiWX3Js",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "9156dd26-58a1-41c9-cdf5-4e9085e33fb8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525532699276,
          "user_tz": -120,
          "elapsed": 11171,
          "user": {
            "displayName": "Gabrijel Boduljak",
            "photoUrl": "//lh5.googleusercontent.com/-PD9SrWcnqqA/AAAAAAAAAAI/AAAAAAAAAog/cQI0fcnyp_g/s50-c-k-no/photo.jpg",
            "userId": "107143472008987249570"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install keras\n",
        "!pip install sklearn\n",
        "!pip install matplotlib\n",
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.1.6)\r\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.12)\r\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (0.19.1)\r\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.3)\r\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\r\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.7.1)\n",
            "Collecting sklearn\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.19.1)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Running setup.py bdist_wheel for sklearn ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (2.1.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.2.0)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.14.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2018.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xlKzkDJFrjA-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cce7c14d-043c-4af5-acb6-df706c4bcf8d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525532706899,
          "user_tz": -120,
          "elapsed": 7577,
          "user": {
            "displayName": "Gabrijel Boduljak",
            "photoUrl": "//lh5.googleusercontent.com/-PD9SrWcnqqA/AAAAAAAAAAI/AAAAAAAAAog/cQI0fcnyp_g/s50-c-k-no/photo.jpg",
            "userId": "107143472008987249570"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "K.clear_session()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "eQEKwl4oAxO7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "cfg = K.tf.ConfigProto()\n",
        "cfg.gpu_options.allow_growth = True\n",
        "K.set_session(K.tf.Session(config=cfg))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "12M0egCCX-27",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4lN2WTUEYBYv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "file_import = drive.CreateFile({'id':'1p1bsltfTcIrZ_kfE6kwGTPzcdXorHbb2'})\n",
        "file_import.GetContentFile('colab_setup.py') \n",
        "from colab_setup import setup\n",
        "\n",
        "setup(drive)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cHBlD0tVj2TY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4fba764f-1f2f-496b-e7b8-a917e1afb02e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525532767419,
          "user_tz": -120,
          "elapsed": 1676,
          "user": {
            "displayName": "Gabrijel Boduljak",
            "photoUrl": "//lh5.googleusercontent.com/-PD9SrWcnqqA/AAAAAAAAAAI/AAAAAAAAAog/cQI0fcnyp_g/s50-c-k-no/photo.jpg",
            "userId": "107143472008987249570"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "colab_setup.py\t\t\t roc_auc_callback.py\tX_train.npy\r\n",
            "custom_fast_text_embeddings.npy  sample_submission.csv\tX_val.npy\r\n",
            "datalab\t\t\t\t train_model.py\t\ty_test.npy\r\n",
            "fast_text_embeddings.npy\t X_submission.npy\ty_train_full.npy\r\n",
            "plot_history.py\t\t\t X_test.npy\t\ty_train.npy\r\n",
            "__pycache__\t\t\t X_train_full.npy\ty_val.npy\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yMwWPTMYXyno",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from plot_history import plot_history\n",
        "from roc_auc_callback import RocAucCallback\n",
        "from train_model import train_with_cv, train_with_submitting, evaluate_on_test\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from keras.layers.merge import concatenate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MIWjPi9bs5d4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def yoon_kim_conv_layer(filtersNumber, inputLayer):\n",
        "    block_1_conv_1 = Conv1D(filtersNumber, 1, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(inputLayer)\n",
        "    block_1_batchnorm1 = BatchNormalization()(block_1_conv_1)\n",
        "    block_1_max_pool1 = MaxPooling1D()(block_1_batchnorm1)\n",
        "    \n",
        "    block_1_conv_2 = Conv1D(filtersNumber, 2, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(inputLayer)\n",
        "    block_1_batchnorm2 = BatchNormalization()(block_1_conv_2)\n",
        "    block_1_max_pool2 = MaxPooling1D()(block_1_batchnorm2)\n",
        "\n",
        "    block_1_conv_3 = Conv1D(filtersNumber, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(inputLayer)\n",
        "    block_1_batchnorm3 = BatchNormalization()(block_1_conv_3)\n",
        "    block_1_max_pool3 = MaxPooling1D()(block_1_batchnorm3)\n",
        "\n",
        "    block_1_conv_4 = Conv1D(filtersNumber, 5, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(inputLayer)\n",
        "    block_1_batchnorm4 = BatchNormalization()(block_1_conv_4)\n",
        "    block_1_max_pool4 = MaxPooling1D()(block_1_batchnorm4)\n",
        "\n",
        "    block_1_features = concatenate([block_1_max_pool1, block_1_max_pool2, block_1_max_pool3, block_1_max_pool4])\n",
        "    block_1_features = Dropout(0.2)(block_1_features)\n",
        "    \n",
        "    return block_1_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LTFG7OgsXynw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 3114
        },
        "outputId": "96130d98-c32d-4c83-ed19-4728b60c8cf2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525532773487,
          "user_tz": -120,
          "elapsed": 4286,
          "user": {
            "displayName": "Gabrijel Boduljak",
            "photoUrl": "//lh5.googleusercontent.com/-PD9SrWcnqqA/AAAAAAAAAAI/AAAAAAAAAog/cQI0fcnyp_g/s50-c-k-no/photo.jpg",
            "userId": "107143472008987249570"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "maxWords = 30000\n",
        "maxSequenceLengthInWords = 400\n",
        "embeddingDimension = 300\n",
        "filtersNumber = 64\n",
        "\n",
        "input_layer = Input(shape=(maxSequenceLengthInWords,))\n",
        "\n",
        "pretrained_embedding_layer = Embedding(\n",
        "    maxWords, \n",
        "    output_dim=embeddingDimension, \n",
        "    input_length=maxSequenceLengthInWords,\n",
        "    weights = [np.load('fast_text_embeddings.npy')],\n",
        "    trainable = False\n",
        ")(input_layer)\n",
        "pretrained_embedding_layer = SpatialDropout1D(0.2)(pretrained_embedding_layer)\n",
        "\n",
        "custom_embedding_layer = Embedding(\n",
        "    maxWords, \n",
        "    output_dim=embeddingDimension, \n",
        "    input_length=maxSequenceLengthInWords,\n",
        "    weights = [np.load('custom_fast_text_embeddings.npy')],\n",
        "    trainable = False\n",
        ")(input_layer)\n",
        "custom_embedding_layer = SpatialDropout1D(0.2)(custom_embedding_layer)\n",
        "\n",
        "embedding = Add()([pretrained_embedding_layer, custom_embedding_layer])\n",
        "embedding_dropout = SpatialDropout1D(0.2)(embedding)\n",
        "\n",
        "bidirectional = Bidirectional(GRU(150, dropout = 0.2, recurrent_dropout = 0.2, return_sequences=True))(embedding_dropout)\n",
        "bidirectional_normalization = BatchNormalization()(bidirectional)\n",
        "bidirectional_dropout = SpatialDropout1D(0.2)(bidirectional_normalization)\n",
        "bidirectional_avg_pool = GlobalAveragePooling1D()(bidirectional_normalization)\n",
        "bidirectional_max_pool = GlobalMaxPooling1D()(bidirectional_normalization)\n",
        "bidirectional_gru_outs = concatenate([bidirectional_avg_pool, bidirectional_max_pool])\n",
        "\n",
        "block_1_features = yoon_kim_conv_layer(filtersNumber, bidirectional_dropout)\n",
        "block_2_features = yoon_kim_conv_layer(filtersNumber * 2, block_1_features)\n",
        "block_3_features = yoon_kim_conv_layer(filtersNumber * 4, block_2_features)\n",
        "\n",
        "block_4_conv_1 = Conv1D(filtersNumber * 8, 1, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(block_3_features)\n",
        "block_4_batchnorm1 = BatchNormalization()(block_4_conv_1)\n",
        "block_4_max_pool1 = GlobalMaxPooling1D()(block_4_batchnorm1)\n",
        "\n",
        "block_4_conv_2 = Conv1D(filtersNumber * 8, 2, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(block_3_features)\n",
        "block_4_batchnorm2 = BatchNormalization()(block_4_conv_2)\n",
        "block_4_max_pool2 = GlobalMaxPooling1D()(block_4_batchnorm2)\n",
        "\n",
        "block_4_conv_3 = Conv1D(filtersNumber * 8, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(block_3_features)\n",
        "block_4_batchnorm3 = BatchNormalization()(block_4_conv_3)\n",
        "block_4_max_pool3 = GlobalMaxPooling1D()(block_4_batchnorm3)\n",
        "\n",
        "block_4_conv_4 = Conv1D(filtersNumber * 8, 5, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(block_3_features)\n",
        "block_4_batchnorm4 = BatchNormalization()(block_4_conv_4)\n",
        "block_4_max_pool4 = GlobalMaxPooling1D()(block_4_batchnorm4)\n",
        "\n",
        "block_4_features = concatenate([block_4_max_pool1, block_4_max_pool2, block_4_max_pool3, block_4_max_pool4])\n",
        "block_4_features = Dropout(0.2)(block_4_features)\n",
        "\n",
        "features = concatenate([block_4_features, bidirectional_gru_outs])\n",
        "features_dropout = Dropout(0.2)(features)\n",
        "\n",
        "dense_1 = Dense(256, activation = 'elu')(features_dropout)\n",
        "dense_1_normalization = BatchNormalization()(dense_1)\n",
        "dense_1_dropout = Dropout(0.2)(dense_1_normalization)\n",
        "\n",
        "dense_2 = Dense(256, activation = 'elu')(dense_1_dropout)\n",
        "dense_2_normalization = BatchNormalization()(dense_2)\n",
        "dense_2_dropout = Dropout(0.2)(dense_2_normalization)\n",
        "\n",
        "output_layer = Dense(6, activation='sigmoid')(dense_2_dropout)\n",
        "\n",
        "model = Model(inputs=[input_layer], outputs=[output_layer])\n",
        "            \n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy', \n",
        "    optimizer='Adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`NHWC` for data_format is deprecated, use `NWC` instead\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 400)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 400, 300)     9000000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 400, 300)     9000000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_1 (SpatialDro (None, 400, 300)     0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_2 (SpatialDro (None, 400, 300)     0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 400, 300)     0           spatial_dropout1d_1[0][0]        \n",
            "                                                                 spatial_dropout1d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_3 (SpatialDro (None, 400, 300)     0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 400, 300)     405900      spatial_dropout1d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 400, 300)     1200        bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_4 (SpatialDro (None, 400, 300)     0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 400, 64)      19264       spatial_dropout1d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 400, 64)      38464       spatial_dropout1d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 400, 64)      57664       spatial_dropout1d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 400, 64)      96064       spatial_dropout1d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 400, 64)      256         conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 400, 64)      256         conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 400, 64)      256         conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 400, 64)      256         conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 200, 64)      0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, 200, 64)      0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, 200, 64)      0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1D)  (None, 200, 64)      0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 200, 256)     0           max_pooling1d_1[0][0]            \n",
            "                                                                 max_pooling1d_2[0][0]            \n",
            "                                                                 max_pooling1d_3[0][0]            \n",
            "                                                                 max_pooling1d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 200, 256)     0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 200, 128)     32896       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 200, 128)     65664       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 200, 128)     98432       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 200, 128)     163968      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 200, 128)     512         conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 200, 128)     512         conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 200, 128)     512         conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 200, 128)     512         conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1D)  (None, 100, 128)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1D)  (None, 100, 128)     0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1D)  (None, 100, 128)     0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1D)  (None, 100, 128)     0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 100, 512)     0           max_pooling1d_5[0][0]            \n",
            "                                                                 max_pooling1d_6[0][0]            \n",
            "                                                                 max_pooling1d_7[0][0]            \n",
            "                                                                 max_pooling1d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 100, 512)     0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_9 (Conv1D)               (None, 100, 256)     131328      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_10 (Conv1D)              (None, 100, 256)     262400      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_11 (Conv1D)              (None, 100, 256)     393472      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_12 (Conv1D)              (None, 100, 256)     655616      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 100, 256)     1024        conv1d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 100, 256)     1024        conv1d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 100, 256)     1024        conv1d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 100, 256)     1024        conv1d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_9 (MaxPooling1D)  (None, 50, 256)      0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling1D) (None, 50, 256)      0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_11 (MaxPooling1D) (None, 50, 256)      0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_12 (MaxPooling1D) (None, 50, 256)      0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 50, 1024)     0           max_pooling1d_9[0][0]            \n",
            "                                                                 max_pooling1d_10[0][0]           \n",
            "                                                                 max_pooling1d_11[0][0]           \n",
            "                                                                 max_pooling1d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 50, 1024)     0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_13 (Conv1D)              (None, 50, 512)      524800      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_14 (Conv1D)              (None, 50, 512)      1049088     dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_15 (Conv1D)              (None, 50, 512)      1573376     dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_16 (Conv1D)              (None, 50, 512)      2621952     dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 50, 512)      2048        conv1d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 50, 512)      2048        conv1d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 50, 512)      2048        conv1d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 50, 512)      2048        conv1d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 512)          0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_3 (GlobalM (None, 512)          0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_4 (GlobalM (None, 512)          0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_5 (GlobalM (None, 512)          0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 2048)         0           global_max_pooling1d_2[0][0]     \n",
            "                                                                 global_max_pooling1d_3[0][0]     \n",
            "                                                                 global_max_pooling1d_4[0][0]     \n",
            "                                                                 global_max_pooling1d_5[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_1 (Glo (None, 300)          0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 300)          0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 2048)         0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 600)          0           global_average_pooling1d_1[0][0] \n",
            "                                                                 global_max_pooling1d_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 2648)         0           dropout_4[0][0]                  \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 2648)         0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          678144      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 256)          1024        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 256)          0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 256)          65792       dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 256)          1024        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 256)          0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 6)            1542        dropout_7[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 26,954,434\n",
            "Trainable params: 8,945,130\n",
            "Non-trainable params: 18,009,304\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xwMmTewgXynz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "1c0cdd91-5299-4a04-f082-ab78bfb380ce"
      },
      "cell_type": "code",
      "source": [
        "history = train_with_cv(model, batchSize=64, rocEvery = 2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 102124 samples, validate on 25532 samples\n",
            "Epoch 1/32\n",
            " 42560/102124 [===========>..................] - ETA: 30:09 - loss: 0.1657 - acc: 0.9396"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102124/102124 [==============================] - 3314s 32ms/step - loss: 0.1045 - acc: 0.9624 - val_loss: 0.0497 - val_acc: 0.9819\n",
            "Epoch 2/32\n",
            "  4992/102124 [>.............................] - ETA: 49:23 - loss: 0.0563 - acc: 0.9804"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0552 - acc: 0.9799"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102124/102124 [==============================] - 3326s 33ms/step - loss: 0.0552 - acc: 0.9799 - val_loss: 0.0526 - val_acc: 0.9817\n",
            "roc-auc: 0.9821 - roc-auc_val: 0.9783                                                                                                    \n",
            "Epoch 3/32\n",
            " 17280/102124 [====>.........................] - ETA: 43:08 - loss: 0.0513 - acc: 0.9806"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0508 - acc: 0.9810"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r102124/102124 [==============================] - 3327s 33ms/step - loss: 0.0507 - acc: 0.9810 - val_loss: 0.0434 - val_acc: 0.9835\n",
            "Epoch 4/32\n",
            " 20160/102124 [====>.........................] - ETA: 41:34 - loss: 0.0485 - acc: 0.9818"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0482 - acc: 0.9818"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102124/102124 [==============================] - 3284s 32ms/step - loss: 0.0482 - acc: 0.9818 - val_loss: 0.0427 - val_acc: 0.9840\n",
            "roc-auc: 0.9876 - roc-auc_val: 0.9837                                                                                                    \n",
            "Epoch 5/32\n",
            " 17280/102124 [====>.........................] - ETA: 42:00 - loss: 0.0481 - acc: 0.9817"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0464 - acc: 0.9824"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r102124/102124 [==============================] - 3264s 32ms/step - loss: 0.0464 - acc: 0.9823 - val_loss: 0.0411 - val_acc: 0.9842\n",
            "Epoch 6/32\n",
            " 20160/102124 [====>.........................] - ETA: 41:34 - loss: 0.0438 - acc: 0.9830"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0444 - acc: 0.9829"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102124/102124 [==============================] - 3304s 32ms/step - loss: 0.0444 - acc: 0.9828 - val_loss: 0.0413 - val_acc: 0.9839\n",
            "roc-auc: 0.989 - roc-auc_val: 0.9866                                                                                                    \n",
            "Epoch 7/32\n",
            " 17344/102124 [====>.........................] - ETA: 43:00 - loss: 0.0440 - acc: 0.9833"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0435 - acc: 0.9833"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r102124/102124 [==============================] - 3314s 32ms/step - loss: 0.0435 - acc: 0.9833 - val_loss: 0.0400 - val_acc: 0.9846\n",
            "Epoch 8/32\n",
            " 20160/102124 [====>.........................] - ETA: 41:26 - loss: 0.0418 - acc: 0.9837"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0424 - acc: 0.9835"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102124/102124 [==============================] - 3302s 32ms/step - loss: 0.0424 - acc: 0.9835 - val_loss: 0.0407 - val_acc: 0.9845\n",
            "roc-auc: 0.9914 - roc-auc_val: 0.9867                                                                                                    \n",
            "Epoch 9/32\n",
            " 17280/102124 [====>.........................] - ETA: 42:52 - loss: 0.0427 - acc: 0.9829"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0416 - acc: 0.9837"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r102124/102124 [==============================] - 3299s 32ms/step - loss: 0.0415 - acc: 0.9837 - val_loss: 0.0399 - val_acc: 0.9847\n",
            "Epoch 10/32\n",
            " 20096/102124 [====>.........................] - ETA: 41:19 - loss: 0.0414 - acc: 0.9836"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102080/102124 [============================>.] - ETA: 1s - loss: 0.0404 - acc: 0.9841"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "102124/102124 [==============================] - 3293s 32ms/step - loss: 0.0404 - acc: 0.9840 - val_loss: 0.0397 - val_acc: 0.9848\n",
            "roc-auc: 0.9924 - roc-auc_val: 0.9883                                                                                                    \n",
            "Epoch 11/32\n",
            " 13440/102124 [==>...........................] - ETA: 44:44 - loss: 0.0394 - acc: 0.9838"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Phpqwrgv2EIL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plot_history(nistory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YuXJYUnX2OAX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(evaluate_on_test(model))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}