{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12075,
     "status": "ok",
     "timestamp": 1530709053177,
     "user": {
      "displayName": "Deep Learning",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115257841230779963257"
     },
     "user_tz": -120
    },
    "id": "yS1FnhiWX3Js",
    "outputId": "ad352659-6fe9-4681-d2fb-55eee0f0877f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.1.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (0.19.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.12)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.5)\n",
      "Collecting sklearn\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.19.1)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Running setup.py bdist_wheel for sklearn ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (2.1.2)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2018.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.14.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.2.0)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install sklearn\n",
    "!pip install matplotlib\n",
    "!pip install -U -q PyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8356,
     "status": "ok",
     "timestamp": 1530709061565,
     "user": {
      "displayName": "Deep Learning",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115257841230779963257"
     },
     "user_tz": -120
    },
    "id": "xlKzkDJFrjA-",
    "outputId": "fcb2b9af-0371-49a1-ea91-f276093f44ba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eQEKwl4oAxO7"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "cfg = K.tf.ConfigProto()\n",
    "cfg.gpu_options.allow_growth = True\n",
    "K.set_session(K.tf.Session(config=cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "12M0egCCX-27"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4lN2WTUEYBYv"
   },
   "outputs": [],
   "source": [
    "file_import = drive.CreateFile({'id':'1p1bsltfTcIrZ_kfE6kwGTPzcdXorHbb2'})\n",
    "file_import.GetContentFile('colab_setup.py') \n",
    "from colab_setup import setup\n",
    "\n",
    "setup(drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1612,
     "status": "ok",
     "timestamp": 1530709106324,
     "user": {
      "displayName": "Deep Learning",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115257841230779963257"
     },
     "user_tz": -120
    },
    "id": "cHBlD0tVj2TY",
    "outputId": "0009ec65-daed-4315-86af-5e27666d410c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colab_setup.py\t\t\t roc_auc_callback.py\tX_train.npy\r\n",
      "custom_fast_text_embeddings.npy  sample_submission.csv\tX_val.npy\r\n",
      "datalab\t\t\t\t train_model.py\t\ty_test.npy\r\n",
      "fast_text_embeddings.npy\t X_submission.npy\ty_train_full.npy\r\n",
      "plot_history.py\t\t\t X_test.npy\t\ty_train.npy\r\n",
      "__pycache__\t\t\t X_train_full.npy\ty_val.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yMwWPTMYXyno"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from plot_history import plot_history\n",
    "from roc_auc_callback import RocAucCallback\n",
    "from train_model import train_with_cv, train_with_submitting, evaluate_on_test\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3YXiQ6IRovcY"
   },
   "outputs": [],
   "source": [
    "file_import = drive.CreateFile({'id':'15j1Nou6m5WNLejJQrUcty6U03xsIgIAI'})\n",
    "file_import.GetContentFile('SelfAttention.py') \n",
    "\n",
    "from SelfAttention import SelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MIWjPi9bs5d4"
   },
   "outputs": [],
   "source": [
    "def one_by_one(filtersNumber, inputLayer, dropout = 0.2):\n",
    "    one_by_one = Conv1D(filtersNumber, 1, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(inputLayer)\n",
    "    one_by_one = BatchNormalization()(one_by_one)\n",
    "    one_by_one = SpatialDropout1D(dropout)(one_by_one)\n",
    "    \n",
    "    return one_by_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mRg7bBAFoL7b"
   },
   "outputs": [],
   "source": [
    "def yoon_kim_feature_extractor(filtersNumber, inputLayer):\n",
    "    block_1_conv_1 = Conv1D(filtersNumber, 1, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(inputLayer)\n",
    "    block_1_batchnorm1 = BatchNormalization()(block_1_conv_1)\n",
    "    block_1_max_pool1 = GlobalMaxPooling1D()(block_1_batchnorm1)\n",
    "\n",
    "    block_1_conv_2 = Conv1D(filtersNumber, 2, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(inputLayer)\n",
    "    block_1_batchnorm2 = BatchNormalization()(block_1_conv_2)\n",
    "    block_1_max_pool2 = GlobalMaxPooling1D()(block_1_batchnorm2)\n",
    "\n",
    "    block_1_conv_3 = Conv1D(filtersNumber, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(inputLayer)\n",
    "    block_1_batchnorm3 = BatchNormalization()(block_1_conv_3)\n",
    "    block_1_max_pool3 = GlobalMaxPooling1D()(block_1_batchnorm3)\n",
    "\n",
    "    block_1_conv_4 = Conv1D(filtersNumber, 5, activation = 'elu', padding = 'same', kernel_initializer = 'he_uniform')(inputLayer)\n",
    "    block_1_batchnorm4 = BatchNormalization()(block_1_conv_4)\n",
    "    block_1_max_pool4 = GlobalMaxPooling1D()(block_1_batchnorm4)\n",
    "\n",
    "    block_1_features = concatenate([\n",
    "        block_1_max_pool1, \n",
    "        block_1_max_pool2, \n",
    "        block_1_max_pool3, \n",
    "        block_1_max_pool4\n",
    "    ])\n",
    "    block_1_features = Dropout(0.2)(block_1_features)\n",
    "    return block_1_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2t9jNZJXg6Zz"
   },
   "outputs": [],
   "source": [
    "def single_category_regressor(features, context, unitsNumber = 64):\n",
    "    features = concatenate([features, context])\n",
    "    \n",
    "    dense_1 = Dense(unitsNumber, activation = 'elu')(features)\n",
    "    dense_1_normalization = BatchNormalization()(dense_1)\n",
    "    dense_1_dropout = Dropout(0.2)(dense_1_normalization)\n",
    "\n",
    "    dense_2 = Dense(unitsNumber, activation = 'elu')(dense_1_dropout)\n",
    "    dense_2_normalization = BatchNormalization()(dense_2)\n",
    "    dense_2_dropout = Dropout(0.2)(dense_2_normalization)\n",
    "    \n",
    "    return Dense(1, activation='sigmoid')(dense_2_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3400
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4260,
     "status": "ok",
     "timestamp": 1530709114322,
     "user": {
      "displayName": "Deep Learning",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115257841230779963257"
     },
     "user_tz": -120
    },
    "id": "LTFG7OgsXynw",
    "outputId": "f7e5d9e1-22af-4604-940d-5d8d0a9b1685"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 400)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 400, 300)     9000000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 400, 300)     9000000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 400, 300)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 400, 300)     0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "average_1 (Average)             (None, 400, 300)     0           spatial_dropout1d_1[0][0]        \n",
      "                                                                 spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 400, 300)     0           average_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_1 (SelfAttention (None, 400, 300)     90601       spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 400, 300)     90300       self_attention_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 400, 300)     1200        conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 400, 300)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 400, 300)     90300       spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 400, 300)     1200        conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 400, 300)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 400, 300)     90300       spatial_dropout1d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 400, 300)     1200        conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 400, 300)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 400, 300)     90300       spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 400, 300)     180300      spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 400, 300)     270300      spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 400, 300)     450300      spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 400, 300)     1200        conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 400, 300)     1200        conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 400, 300)     1200        conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 400, 300)     1200        conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 300)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 300)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 300)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 300)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1200)         0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1200)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          307456      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 256)          1024        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          65792       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 256)          1024        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256)          0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1456)         0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1456)         0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1456)         0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1456)         0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1456)         0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1456)         0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           93248       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           93248       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 64)           93248       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 64)           93248       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 64)           93248       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 64)           93248       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64)           256         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64)           256         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64)           256         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64)           256         dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 64)           256         dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 64)           256         dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64)           0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64)           0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 64)           0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 64)           0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 64)           0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 64)           0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           4160        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 64)           4160        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 64)           4160        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 64)           4160        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 64)           4160        dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 64)           4160        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64)           256         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64)           256         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64)           256         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64)           256         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 64)           256         dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 64)           256         dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 64)           0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64)           0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 64)           0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 64)           0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 64)           0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 64)           0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            65          dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            65          dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            65          dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1)            65          dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 1)            65          dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1)            65          dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 6)            1542        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 6)            0           dense_8[0][0]                    \n",
      "                                                                 dense_11[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "                                                                 dense_17[0][0]                   \n",
      "                                                                 dense_20[0][0]                   \n",
      "                                                                 dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 6)            0           dense_5[0][0]                    \n",
      "                                                                 concatenate_8[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 20,325,849\n",
      "Trainable params: 2,319,089\n",
      "Non-trainable params: 18,006,760\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "maxWords = 30000\n",
    "maxSequenceLengthInWords = 400\n",
    "embeddingDimension = 300\n",
    "filtersNumber = 300\n",
    "\n",
    "input_layer = Input(shape=(maxSequenceLengthInWords,))\n",
    "\n",
    "pretrained_embedding_layer = Embedding(\n",
    "    maxWords, \n",
    "    output_dim=embeddingDimension, \n",
    "    input_length=maxSequenceLengthInWords,\n",
    "    weights = [np.load('fast_text_embeddings.npy')],\n",
    "    trainable = False\n",
    ")(input_layer)\n",
    "pretrained_embedding_layer = SpatialDropout1D(0.2)(pretrained_embedding_layer)\n",
    "\n",
    "custom_embedding_layer = Embedding(\n",
    "    maxWords, \n",
    "    output_dim=embeddingDimension, \n",
    "    input_length=maxSequenceLengthInWords,\n",
    "    weights = [np.load('custom_fast_text_embeddings.npy')],\n",
    "    trainable = False\n",
    ")(input_layer)\n",
    "custom_embedding_layer = SpatialDropout1D(0.2)(custom_embedding_layer)\n",
    "\n",
    "embedding = Average()([pretrained_embedding_layer, custom_embedding_layer])\n",
    "embedding_dropout = SpatialDropout1D(0.2)(embedding)\n",
    "\n",
    "embedding_dropout = SelfAttention()(embedding_dropout)\n",
    "\n",
    "features_1 = one_by_one(filtersNumber, embedding_dropout)\n",
    "features_2 = one_by_one(filtersNumber, features_1)\n",
    "features_3 = one_by_one(filtersNumber, features_2)\n",
    "\n",
    "features = yoon_kim_feature_extractor(filtersNumber, features_3)\n",
    "\n",
    "\n",
    "dense_1 = Dense(256, activation = 'elu')(features)\n",
    "dense_1_normalization = BatchNormalization()(dense_1)\n",
    "dense_1_dropout = Dropout(0.2)(dense_1_normalization)\n",
    "\n",
    "dense_2 = Dense(256, activation = 'elu')(dense_1_dropout)\n",
    "dense_2_normalization = BatchNormalization()(dense_2)\n",
    "dense_2_dropout = Dropout(0.2)(dense_2_normalization)\n",
    "\n",
    "output_layer = Dense(6, activation='sigmoid')(dense_2_dropout)\n",
    "\n",
    "single_category_layer = concatenate([\n",
    "    single_category_regressor(features, dense_2_dropout, 64),\n",
    "    single_category_regressor(features, dense_2_dropout, 64),\n",
    "    single_category_regressor(features, dense_2_dropout, 64),\n",
    "    single_category_regressor(features, dense_2_dropout, 64),\n",
    "    single_category_regressor(features, dense_2_dropout, 64),\n",
    "    single_category_regressor(features, dense_2_dropout, 64),\n",
    "])\n",
    "\n",
    "output_layer = add([output_layer, single_category_layer])\n",
    "\n",
    "model = Model(inputs=[input_layer], outputs=[output_layer])\n",
    "            \n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1516
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24052922,
     "status": "ok",
     "timestamp": 1530733167306,
     "user": {
      "displayName": "Deep Learning",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115257841230779963257"
     },
     "user_tz": -120
    },
    "id": "xwMmTewgXynz",
    "outputId": "90affa06-ca86-4bf8-c0e1-fdc5615fce30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 102124 samples, validate on 25532 samples\n",
      "Epoch 1/32\n",
      " 20864/102124 [=====>........................] - ETA: 8:39 - loss: 4.5988 - acc: 0.4996 63744/102124 [=================>............] - ETA: 3:54 - loss: 2.0006 - acc: 0.7537100224/102124 [============================>.] - ETA: 11s - loss: 1.3362 - acc: 0.8290102124/102124 [==============================] - 659s 6ms/step - loss: 1.3138 - acc: 0.8316 - val_loss: 0.0981 - val_acc: 0.9731\n",
      "Epoch 2/32\n",
      " 13280/102124 [==>...........................] - ETA: 8:51 - loss: 0.1404 - acc: 0.9652 57952/102124 [================>.............] - ETA: 4:23 - loss: 0.1224 - acc: 0.9668 96736/102124 [===========================>..] - ETA: 32s - loss: 0.1086 - acc: 0.9691102124/102124 [==============================] - 650s 6ms/step - loss: 0.1071 - acc: 0.9694 - val_loss: 0.0802 - val_acc: 0.9746\n",
      "roc-auc: 0.963 - roc-auc_val: 0.957                                                                                                    \n",
      "Epoch 3/32\n",
      "  7488/102124 [=>............................] - ETA: 9:24 - loss: 0.0788 - acc: 0.9747 45024/102124 [============>.................] - ETA: 5:40 - loss: 0.0741 - acc: 0.9757 84960/102124 [=======================>......] - ETA: 1:42 - loss: 0.0722 - acc: 0.9760102124/102124 [==============================] - 651s 6ms/step - loss: 0.0714 - acc: 0.9761 - val_loss: 0.1740 - val_acc: 0.9628\n",
      "Epoch 4/32\n",
      "  7264/102124 [=>............................] - ETA: 9:27 - loss: 0.0696 - acc: 0.9761 44256/102124 [============>.................] - ETA: 5:46 - loss: 0.0639 - acc: 0.9780 84896/102124 [=======================>......] - ETA: 1:43 - loss: 0.0618 - acc: 0.9784102124/102124 [==============================] - 652s 6ms/step - loss: 0.0619 - acc: 0.9782 - val_loss: 0.0558 - val_acc: 0.9809\n",
      "roc-auc: 0.9811 - roc-auc_val: 0.9778                                                                                                    \n",
      "Epoch 5/32\n",
      "  4544/102124 [>.............................] - ETA: 9:41 - loss: 0.0563 - acc: 0.9794 46272/102124 [============>.................] - ETA: 5:33 - loss: 0.0584 - acc: 0.9788 82624/102124 [=======================>......] - ETA: 1:56 - loss: 0.0585 - acc: 0.9789102124/102124 [==============================] - 651s 6ms/step - loss: 0.0578 - acc: 0.9791 - val_loss: 0.0598 - val_acc: 0.9804\n",
      "Epoch 6/32\n",
      "  6432/102124 [>.............................] - ETA: 9:33 - loss: 0.0546 - acc: 0.9791 44096/102124 [===========>..................] - ETA: 5:47 - loss: 0.0555 - acc: 0.9796 84064/102124 [=======================>......] - ETA: 1:48 - loss: 0.0541 - acc: 0.9800102124/102124 [==============================] - 652s 6ms/step - loss: 0.0537 - acc: 0.9801 - val_loss: 0.0893 - val_acc: 0.9755\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00029730176902376115.\n",
      "roc-auc: 0.9749 - roc-auc_val: 0.9746                                                                                                    \n",
      "Epoch 7/32\n",
      "  3520/102124 [>.............................] - ETA: 9:48 - loss: 0.0527 - acc: 0.9804 43232/102124 [===========>..................] - ETA: 5:52 - loss: 0.0509 - acc: 0.9808 81024/102124 [======================>.......] - ETA: 2:06 - loss: 0.0505 - acc: 0.9809102124/102124 [==============================] - 652s 6ms/step - loss: 0.0507 - acc: 0.9809 - val_loss: 0.0811 - val_acc: 0.9761\n",
      "Epoch 8/32\n",
      "  5792/102124 [>.............................] - ETA: 9:36 - loss: 0.0454 - acc: 0.9829 43360/102124 [===========>..................] - ETA: 5:51 - loss: 0.0493 - acc: 0.9813 82944/102124 [=======================>......] - ETA: 1:54 - loss: 0.0486 - acc: 0.9816102124/102124 [==============================] - 652s 6ms/step - loss: 0.0488 - acc: 0.9815 - val_loss: 0.0492 - val_acc: 0.9816\n",
      "roc-auc: 0.9818 - roc-auc_val: 0.9797                                                                                                    \n",
      "Epoch 9/32\n",
      "  4096/102124 [>.............................] - ETA: 9:42 - loss: 0.0450 - acc: 0.9827 41056/102124 [===========>..................] - ETA: 6:03 - loss: 0.0480 - acc: 0.9821 81792/102124 [=======================>......] - ETA: 2:01 - loss: 0.0480 - acc: 0.9820102124/102124 [==============================] - 650s 6ms/step - loss: 0.0476 - acc: 0.9820 - val_loss: 0.0432 - val_acc: 0.9839\n",
      "Epoch 10/32\n",
      "  5984/102124 [>.............................] - ETA: 9:35 - loss: 0.0456 - acc: 0.9822 41600/102124 [===========>..................] - ETA: 6:02 - loss: 0.0466 - acc: 0.9822 77984/102124 [=====================>........] - ETA: 2:24 - loss: 0.0464 - acc: 0.9824102124/102124 [==============================] - 652s 6ms/step - loss: 0.0463 - acc: 0.9824 - val_loss: 0.1048 - val_acc: 0.9593\n",
      "roc-auc: 0.9795 - roc-auc_val: 0.9745                                                                                                    \n",
      "Epoch 11/32\n",
      "  2848/102124 [..............................] - ETA: 9:52 - loss: 0.0436 - acc: 0.9827 41376/102124 [===========>..................] - ETA: 6:03 - loss: 0.0454 - acc: 0.9829 78336/102124 [======================>.......] - ETA: 2:22 - loss: 0.0455 - acc: 0.9828102124/102124 [==============================] - 652s 6ms/step - loss: 0.0454 - acc: 0.9828 - val_loss: 0.0449 - val_acc: 0.9822\n",
      "Epoch 12/32\n",
      "  4672/102124 [>.............................] - ETA: 9:43 - loss: 0.0454 - acc: 0.9824 42528/102124 [===========>..................] - ETA: 5:56 - loss: 0.0461 - acc: 0.9817 89664/102124 [=========================>....] - ETA: 1:14 - loss: 0.0451 - acc: 0.9825102124/102124 [==============================] - 650s 6ms/step - loss: 0.0451 - acc: 0.9825 - val_loss: 0.0455 - val_acc: 0.9812\n",
      "roc-auc: 0.9898 - roc-auc_val: 0.9868                                                                                                    \n",
      "Epoch 13/32\n",
      "  5632/102124 [>.............................] - ETA: 9:35 - loss: 0.0402 - acc: 0.9835 48800/102124 [=============>................] - ETA: 5:18 - loss: 0.0438 - acc: 0.9829 85792/102124 [========================>.....] - ETA: 1:37 - loss: 0.0439 - acc: 0.9829102124/102124 [==============================] - 652s 6ms/step - loss: 0.0438 - acc: 0.9829 - val_loss: 0.0420 - val_acc: 0.9835\n",
      "Epoch 14/32\n",
      "  7552/102124 [=>............................] - ETA: 9:26 - loss: 0.0434 - acc: 0.9831 46272/102124 [============>.................] - ETA: 5:34 - loss: 0.0435 - acc: 0.9829 83936/102124 [=======================>......] - ETA: 1:48 - loss: 0.0437 - acc: 0.9830102124/102124 [==============================] - 652s 6ms/step - loss: 0.0435 - acc: 0.9831 - val_loss: 0.0418 - val_acc: 0.9842\n",
      "roc-auc: 0.9908 - roc-auc_val: 0.986                                                                                                    \n",
      "Epoch 15/32\n",
      "  4352/102124 [>.............................] - ETA: 9:45 - loss: 0.0418 - acc: 0.9834 53568/102124 [==============>...............] - ETA: 4:50 - loss: 0.0427 - acc: 0.9834 91136/102124 [=========================>....] - ETA: 1:05 - loss: 0.0428 - acc: 0.9834102124/102124 [==============================] - 652s 6ms/step - loss: 0.0428 - acc: 0.9834 - val_loss: 0.0446 - val_acc: 0.9835\n",
      "Epoch 16/32\n",
      "  9696/102124 [=>............................] - ETA: 9:11 - loss: 0.0408 - acc: 0.9842 46976/102124 [============>.................] - ETA: 5:29 - loss: 0.0425 - acc: 0.9835 85760/102124 [========================>.....] - ETA: 1:37 - loss: 0.0424 - acc: 0.9835102124/102124 [==============================] - 651s 6ms/step - loss: 0.0424 - acc: 0.9835 - val_loss: 0.0418 - val_acc: 0.9838\n",
      "roc-auc: 0.986 - roc-auc_val: 0.9799                                                                                                    \n",
      "Epoch 17/32\n",
      "  4640/102124 [>.............................] - ETA: 9:37 - loss: 0.0389 - acc: 0.9844 41376/102124 [===========>..................] - ETA: 6:02 - loss: 0.0409 - acc: 0.9832 79488/102124 [======================>.......] - ETA: 2:15 - loss: 0.0416 - acc: 0.9829102124/102124 [==============================] - 651s 6ms/step - loss: 0.0416 - acc: 0.9829 - val_loss: 0.0410 - val_acc: 0.9842\n",
      "Epoch 18/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5280/102124 [>.............................] - ETA: 9:40 - loss: 0.0438 - acc: 0.9828 45344/102124 [============>.................] - ETA: 5:39 - loss: 0.0405 - acc: 0.9838 84672/102124 [=======================>......] - ETA: 1:44 - loss: 0.0408 - acc: 0.9838102124/102124 [==============================] - 651s 6ms/step - loss: 0.0410 - acc: 0.9838 - val_loss: 0.0413 - val_acc: 0.9844\n",
      "roc-auc: 0.9927 - roc-auc_val: 0.9864                                                                                                    \n",
      "Epoch 19/32\n",
      "  4416/102124 [>.............................] - ETA: 9:43 - loss: 0.0478 - acc: 0.9816 42880/102124 [===========>..................] - ETA: 5:54 - loss: 0.0413 - acc: 0.9838 81696/102124 [======================>.......] - ETA: 2:02 - loss: 0.0408 - acc: 0.9840102124/102124 [==============================] - 651s 6ms/step - loss: 0.0409 - acc: 0.9840 - val_loss: 0.0412 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 7.694652595091611e-05.\n",
      "Epoch 20/32\n",
      "  4320/102124 [>.............................] - ETA: 9:45 - loss: 0.0428 - acc: 0.9836 43808/102124 [===========>..................] - ETA: 5:48 - loss: 0.0403 - acc: 0.9839 80544/102124 [======================>.......] - ETA: 2:09 - loss: 0.0406 - acc: 0.9836102124/102124 [==============================] - 652s 6ms/step - loss: 0.0404 - acc: 0.9837 - val_loss: 0.0411 - val_acc: 0.9836\n",
      "roc-auc: 0.9922 - roc-auc_val: 0.9847                                                                                                    \n",
      "Epoch 21/32\n",
      "  3520/102124 [>.............................] - ETA: 9:43 - loss: 0.0386 - acc: 0.9838 40736/102124 [==========>...................] - ETA: 6:05 - loss: 0.0400 - acc: 0.9835 87296/102124 [========================>.....] - ETA: 1:28 - loss: 0.0395 - acc: 0.9838102124/102124 [==============================] - 648s 6ms/step - loss: 0.0397 - acc: 0.9837 - val_loss: 0.0419 - val_acc: 0.9836\n",
      "Epoch 22/32\n",
      "  8224/102124 [=>............................] - ETA: 9:17 - loss: 0.0369 - acc: 0.9840 56544/102124 [===============>..............] - ETA: 4:31 - loss: 0.0402 - acc: 0.9834 97376/102124 [===========================>..] - ETA: 28s - loss: 0.0400 - acc: 0.9833102124/102124 [==============================] - 648s 6ms/step - loss: 0.0399 - acc: 0.9833 - val_loss: 0.0412 - val_acc: 0.9842\n",
      "roc-auc: 0.9926 - roc-auc_val: 0.9849                                                                                                    \n",
      "Epoch 23/32\n",
      "  7456/102124 [=>............................] - ETA: 9:21 - loss: 0.0390 - acc: 0.9837 50304/102124 [=============>................] - ETA: 5:07 - loss: 0.0401 - acc: 0.9835 89632/102124 [=========================>....] - ETA: 1:14 - loss: 0.0397 - acc: 0.9837102124/102124 [==============================] - 647s 6ms/step - loss: 0.0396 - acc: 0.9837 - val_loss: 0.0409 - val_acc: 0.9838\n",
      "Epoch 24/32\n",
      "  9184/102124 [=>............................] - ETA: 9:12 - loss: 0.0406 - acc: 0.9832 46496/102124 [============>.................] - ETA: 5:30 - loss: 0.0395 - acc: 0.9838 95328/102124 [===========================>..] - ETA: 40s - loss: 0.0391 - acc: 0.9841102124/102124 [==============================] - 647s 6ms/step - loss: 0.0391 - acc: 0.9841 - val_loss: 0.0409 - val_acc: 0.9841\n",
      "roc-auc: 0.9942 - roc-auc_val: 0.9874                                                                                                    \n",
      "Epoch 25/32\n",
      "  7040/102124 [=>............................] - ETA: 9:24 - loss: 0.0376 - acc: 0.9841 50784/102124 [=============>................] - ETA: 5:04 - loss: 0.0382 - acc: 0.9843 96000/102124 [===========================>..] - ETA: 36s - loss: 0.0387 - acc: 0.9842102124/102124 [==============================] - 647s 6ms/step - loss: 0.0385 - acc: 0.9843 - val_loss: 0.0407 - val_acc: 0.9840\n",
      "Epoch 26/32\n",
      " 11616/102124 [==>...........................] - ETA: 8:54 - loss: 0.0386 - acc: 0.9841 49280/102124 [=============>................] - ETA: 5:12 - loss: 0.0385 - acc: 0.9842 90656/102124 [=========================>....] - ETA: 1:08 - loss: 0.0388 - acc: 0.9842102124/102124 [==============================] - 646s 6ms/step - loss: 0.0387 - acc: 0.9843 - val_loss: 0.0419 - val_acc: 0.9841\n",
      "roc-auc: 0.9941 - roc-auc_val: 0.9866                                                                                                    \n",
      "Epoch 27/32\n",
      "  5920/102124 [>.............................] - ETA: 9:31 - loss: 0.0378 - acc: 0.9850 44224/102124 [===========>..................] - ETA: 5:43 - loss: 0.0376 - acc: 0.9845102112/102124 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9843102124/102124 [==============================] - 647s 6ms/step - loss: 0.0381 - acc: 0.9843 - val_loss: 0.0412 - val_acc: 0.9843\n",
      "Epoch 28/32\n",
      " 13952/102124 [===>..........................] - ETA: 8:43 - loss: 0.0358 - acc: 0.9855 53248/102124 [==============>...............] - ETA: 4:50 - loss: 0.0373 - acc: 0.9849 91776/102124 [=========================>....] - ETA: 1:01 - loss: 0.0381 - acc: 0.9847102124/102124 [==============================] - 647s 6ms/step - loss: 0.0380 - acc: 0.9847 - val_loss: 0.0413 - val_acc: 0.9843\n",
      "roc-auc: 0.9938 - roc-auc_val: 0.9859                                                                                                    \n",
      "Epoch 29/32\n",
      "  6208/102124 [>.............................] - ETA: 9:29 - loss: 0.0384 - acc: 0.9847 47744/102124 [=============>................] - ETA: 5:22 - loss: 0.0378 - acc: 0.9847 85184/102124 [========================>.....] - ETA: 1:40 - loss: 0.0377 - acc: 0.9846102124/102124 [==============================] - 646s 6ms/step - loss: 0.0376 - acc: 0.9846 - val_loss: 0.0419 - val_acc: 0.9837\n",
      "Epoch 30/32\n",
      "  7360/102124 [=>............................] - ETA: 9:21 - loss: 0.0363 - acc: 0.9846 53056/102124 [==============>...............] - ETA: 4:50 - loss: 0.0376 - acc: 0.9844 89952/102124 [=========================>....] - ETA: 1:12 - loss: 0.0375 - acc: 0.9843102124/102124 [==============================] - 646s 6ms/step - loss: 0.0375 - acc: 0.9842 - val_loss: 0.0421 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.4518252757843584e-05.\n",
      "roc-auc: 0.9927 - roc-auc_val: 0.9843                                                                                                    \n",
      "Epoch 31/32\n",
      "  4736/102124 [>.............................] - ETA: 9:37 - loss: 0.0359 - acc: 0.9850 43232/102124 [===========>..................] - ETA: 5:49 - loss: 0.0377 - acc: 0.9840 83584/102124 [=======================>......] - ETA: 1:49 - loss: 0.0375 - acc: 0.9840102124/102124 [==============================] - 646s 6ms/step - loss: 0.0377 - acc: 0.9838 - val_loss: 0.0413 - val_acc: 0.9833\n",
      "Epoch 32/32\n",
      "  6880/102124 [=>............................] - ETA: 9:26 - loss: 0.0385 - acc: 0.9835 53728/102124 [==============>...............] - ETA: 4:50 - loss: 0.0379 - acc: 0.9838 95680/102124 [===========================>..] - ETA: 38s - loss: 0.0374 - acc: 0.9842102124/102124 [==============================] - 650s 6ms/step - loss: 0.0373 - acc: 0.9843 - val_loss: 0.0416 - val_acc: 0.9839\n",
      "roc-auc: 0.9939 - roc-auc_val: 0.9855                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "history = train_with_cv(model, batchSize=32, rocEvery = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3241,
     "status": "ok",
     "timestamp": 1530733170561,
     "user": {
      "displayName": "Deep Learning",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115257841230779963257"
     },
     "user_tz": -120
    },
    "id": "sms3R-U4469B",
    "outputId": "dcfd2cb3-8cf5-4dc3-e167-7f02a662ac79"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA64AAAEVCAYAAADglLjtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCCGEEEIIUapJ4iqEEEIIIYQQolT7f/V4RYim9RPYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1a501a3400>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 105180,
     "status": "ok",
     "timestamp": 1530733276763,
     "user": {
      "displayName": "Deep Learning",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115257841230779963257"
     },
     "user_tz": -120
    },
    "id": "r2gtMBj2Tp9A",
    "outputId": "432fdbbd-d464-4394-fe5c-07a3222e8ba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31915/31915 [==============================] - 55s 2ms/step\n",
      "([0.03973785038513953, 0.9838999297109756], 0.9879793847394406)\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_on_test(model))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "combined_context_with_each_add_64.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
