{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "import numpy\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from pretrained_models import *\n",
    "from preprocess import preprocess_text, clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'use_only_cpu_compatible_models': True\n",
    "}\n",
    "models_paths = get_serialized_models(config['use_only_cpu_compatible_models'])\n",
    "\n",
    "global models\n",
    "global graph\n",
    "models = [*map(load_model, models_paths)]\n",
    "graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_category_difference(previous_result, new_result):\n",
    "    return abs(previous_result['probability'] - new_result['probability'])\n",
    "\n",
    "def compute_words_importance(text, averaged_most_probable_category):\n",
    "    cleaned_text = clean(text)\n",
    "    words = cleaned_text.split(' ')\n",
    "    \n",
    "    words_with_texts = [\n",
    "        *map(\n",
    "            lambda word: (word, ' '.join([*filter(lambda text_word: text_word != word, words)])), \n",
    "            words\n",
    "        )\n",
    "    ]\n",
    "    results_without_each_word = [\n",
    "        *map(\n",
    "            lambda group: (group[0], get_models_predictions(group[1])['most_probable_category']),\n",
    "            words_with_texts\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    return [\n",
    "        *map(\n",
    "            lambda group: (group[0], compute_category_difference(averaged_most_probable_category, group[1])),\n",
    "            results_without_each_word\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_predictions(text):\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "    labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "    with graph.as_default():\n",
    "        raw_probabilities = [\n",
    "            *map(\n",
    "                lambda model: numpy.squeeze(model.predict(preprocessed_text), axis=0).tolist(),\n",
    "                models\n",
    "            )\n",
    "        ]\n",
    "        probabilities_with_labels = [\n",
    "            *map(\n",
    "                lambda probability: [\n",
    "                    *map(\n",
    "                        lambda i: {'label': labels[i], 'probability': probability[i]},\n",
    "                        range(0, 6)\n",
    "                    )],\n",
    "                raw_probabilities\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    averaged_probabilities = numpy.average(raw_probabilities, axis=0).tolist()\n",
    "\n",
    "    return {\n",
    "        'probabilities_of_models': raw_probabilities,\n",
    "        'probabilities_of_models_with_labels': probabilities_with_labels,\n",
    "        'models_averaged_probabilities': averaged_probabilities,\n",
    "        'most_probable_category': {\n",
    "            'label': labels[numpy.argmax(averaged_probabilities)],\n",
    "            'probability': numpy.max(averaged_probabilities)\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    predictions = get_models_predictions(text)\n",
    "    importances = compute_words_importance(text, predictions['most_probable_category'])\n",
    "    \n",
    "    dto = predictions\n",
    "    dto['word_importances'] = importances\n",
    "    \n",
    "    return dto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models_averaged_probabilities': [0.996890127658844,\n",
       "  0.4814731180667877,\n",
       "  0.9424256980419159,\n",
       "  0.9009456038475037,\n",
       "  0.7575989067554474,\n",
       "  0.018248425796628],\n",
       " 'most_probable_category': {'label': 'toxic',\n",
       "  'probability': 0.996890127658844},\n",
       " 'probabilities_of_models': [[0.9966059923171997,\n",
       "   0.40833544731140137,\n",
       "   0.9401798248291016,\n",
       "   0.9129313826560974,\n",
       "   0.6990986466407776,\n",
       "   0.017510369420051575],\n",
       "  [0.9971742630004883,\n",
       "   0.5546107888221741,\n",
       "   0.9446715712547302,\n",
       "   0.8889598250389099,\n",
       "   0.8160991668701172,\n",
       "   0.018986482173204422]],\n",
       " 'probabilities_of_models_with_labels': [[{'label': 'toxic',\n",
       "    'probability': 0.9966059923171997},\n",
       "   {'label': 'severe_toxic', 'probability': 0.40833544731140137},\n",
       "   {'label': 'obscene', 'probability': 0.9401798248291016},\n",
       "   {'label': 'threat', 'probability': 0.9129313826560974},\n",
       "   {'label': 'insult', 'probability': 0.6990986466407776},\n",
       "   {'label': 'identity_hate', 'probability': 0.017510369420051575}],\n",
       "  [{'label': 'toxic', 'probability': 0.9971742630004883},\n",
       "   {'label': 'severe_toxic', 'probability': 0.5546107888221741},\n",
       "   {'label': 'obscene', 'probability': 0.9446715712547302},\n",
       "   {'label': 'threat', 'probability': 0.8889598250389099},\n",
       "   {'label': 'insult', 'probability': 0.8160991668701172},\n",
       "   {'label': 'identity_hate', 'probability': 0.018986482173204422}]],\n",
       " 'word_importances': [('i', 0.00015231966972351074),\n",
       "  ('will', 0.0004157721996307373),\n",
       "  ('fuckin', 0.039737969636917114),\n",
       "  ('kill', 0.0010592639446258545),\n",
       "  ('you', 0.001063704490661621)]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('I will fuckin kill you!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 0.00015231966972351074),\n",
       " ('will', 0.0004157721996307373),\n",
       " ('fuckin', 0.039737969636917114),\n",
       " ('kill', 0.0010592639446258545),\n",
       " ('you', 0.001063704490661621)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_words_importance('I will fuckin kill you!', get_models_predictions('I will fuckin kill you!')['most_probable_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
